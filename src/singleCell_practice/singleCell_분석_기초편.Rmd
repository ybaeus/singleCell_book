---
title: "singleCell_분석_기초"
author: "yeji Bae"
date: "2024-08-03"
output: html_document
---

2023.04.26 복사본. -> 2024.04.27 수정 -> 2024.08.03 cellranger 8.0.0 + seurat v5 

해당 스크립트는 "실전 단일세포 데이터 분석: 예제 코드와 데이터로 배우는 생물정보 분석 기술" 책에서 따라 할 수 있도록 제작된 실습 스크립트 '기초편' 입니다. 

현재 보고 계시는 코드는 카운트 매트릭스 생성 후, 싱글셀 데이터 분석을 위해 슈랏을 이용한 기본 코드이며,조금 더 심화된 코드를 확인 하고 싶다면 singleCell_분석_고급편.Rmd 파일을 확인해주세요.

각 코드블럭에 대한 자세한 설명은 책의 챕터 05부터 챕터 10까지를 참고바랍니다.

질문 사항이 있거나, 코드를 돌리는데 어려움이 있다면 github페이지에서 -> 'issue' 탭 -> 'New issue' 버튼을 클릭해서 작성해주시면 빠른 시일내에 답변드리겠습니다. 

Question: R script or Rmd script? 

```{r setup, include=FALSE} 
# 작업 디렉토리 설정
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file()) 
setwd("/active/taylor_s/people/ybae/RSC/singleCell_book/src")
```

# 데이터 설명 

TODO: 데이터 설명 
TODO: 데이터 구조 설명 
스크립스를 실행하기 전 모든 셀 레인저의 아웃풋 다음과 같은 구조로 저장되어 있어야합니다. 
만약 셀 레인저를 실행하기 어려운 환경이라면 _______ 에서 git clone 을 이용해 다운받아주세요. 

# 코드 실행 
코드를 하이라이트 한 뒤 위쪽 'Run' 버튼을 클릭하거나 command + return 단축키를 이용해서 실행시킬 수 있습니다. 코드 블록 ```{r}``` 에 포함되는 코드들은 해당 블록의 삼각형 버튼을 클릭하면 한번에 실행됩니다. 
TODO: window 단축키? 

# 챕터 5  슈랏 오브젝트, 품질관리 및 필터링"
## 챕터 5.1 슈랏 오브젝트 만들기 
[코드 5-1] 필요한 패키지 설치 및 불러오기
```{r}
# 필요한 패키지 설치  
install.packages("Seurat") 
install.packages("dplyr") 
install.packages("hdf5r")

# 패키지 불러오기  
library(Seurat) 
library(dplyr) 
library(hdf5r)
```

[코드 5-2] 2가지 방법으로 슈랏 오브젝트 생성하기
```{r}
# [1] h5 파일 이용하기
count_SRR13911909.h5 <- Read10X_h5("../data/count_SRR13911909/outs/filtered_feature_bc_matrix.h5")
SRR13911909.h5.sobj_ori <- CreateSeuratObject(counts = count_SRR13911909.h5, project = "pbmc_alzheimer")

# [2] Market Exchange Format(MEX) 구조 폴더 이용하기 
count_SRR13911909 <- Read10X(data.dir =  "../data/count_SRR13911909/outs/filtered_feature_bc_matrix/")
SRR13911909.sobj_ori <- CreateSeuratObject(counts = count_SRR13911909, project = "pbmc_alzheimer")
```

(참고)[코드 5-3] 슈랏 오브젝트 생성 두 가지 방법의 시간 비교해보기  
해당 코드 블럭을 한번에 실행시켜줘야 정확한 시간을 얻을 수 있습니다. 한번에 하이라이트 해서 실행시키거나, 코드 블록의 오른쪽 위 화살표 버튼을 이용해서 실행해주세요. 
```{r}
# [1] h5 파일 이용하기
start <- Sys.time() # 시작 시간 
count_SRR13911909.h5 <- Read10X_h5("../data/count_SRR13911909/outs/filtered_feature_bc_matrix.h5")
SRR13911909.h5.sobj_ori <- CreateSeuratObject(counts = count_SRR13911909.h5, project = "pbmc_alzheimer")
print( Sys.time() - start ) # 현재 시간 – 시작 시간 = 총 걸린 시간 (4.866736 secs)

# [2] Market Exchange Format(MEX) 구조 폴더 이용하기  
start <- Sys.time()
count_SRR13911909 <- Read10X(data.dir = "../data/count_SRR13911909/outs/filtered_feature_bc_matrix/")
SRR13911909.sobj_ori <- CreateSeuratObject(counts = count_SRR13911909, project = "pbmc_alzheimer")
print( Sys.time() - start )
```

[코드 5-4] 모든 샘플을 슈랏 오브젝트로 변형하기 (최소 발현량, 발현 세포 임계값)
```{r}
# 각 샘플의 카운트 메트릭스를 슈랏 오브젝트로 변환하기
count_SRR13911909.h5 <- Read10X_h5("../data/count_SRR13911909/outs/filtered_feature_bc_matrix.h5", use.names = TRUE, unique.features = TRUE)
SRR13911909.h5.sobj <- CreateSeuratObject(counts = count_SRR13911909.h5, project = "pbmc_alzheimer", min.cells = 3, min.features = 200)

count_SRR13911910.h5 <- Read10X_h5("../data/count_SRR13911910/outs/filtered_feature_bc_matrix.h5", use.names = TRUE, unique.features = TRUE)
SRR13911910.h5.sobj <- CreateSeuratObject(counts = count_SRR13911910.h5, project = "pbmc_alzheimer", min.cells = 3, min.features = 200)

count_SRR13911911.h5 <- Read10X_h5("../data/count_SRR13911911/outs/filtered_feature_bc_matrix.h5", use.names = TRUE, unique.features = TRUE)
SRR13911911.h5.sobj <- CreateSeuratObject(counts = count_SRR13911911.h5, project = "pbmc_alzheimer", min.cells = 3, min.features = 200)

count_SRR13911912.h5 <- Read10X_h5("../data/count_SRR13911912/outs/filtered_feature_bc_matrix.h5", use.names = TRUE, unique.features = TRUE)
SRR13911912.h5.sobj <- CreateSeuratObject(counts = count_SRR13911912.h5, project = "pbmc_alzheimer", min.cells = 3, min.features = 200)

count_SRR13911913.h5 <- Read10X_h5("../data/count_SRR13911913/outs/filtered_feature_bc_matrix.h5", use.names = TRUE, unique.features = TRUE)
SRR13911913.h5.sobj <- CreateSeuratObject(counts = count_SRR13911913.h5, project = "pbmc_alzheimer", min.cells = 3, min.features = 200)

count_SRR13911914.h5 <- Read10X_h5("../data/count_SRR13911914/outs/filtered_feature_bc_matrix.h5", use.names = TRUE, unique.features = TRUE)
SRR13911914.h5.sobj <- CreateSeuratObject(counts = count_SRR13911914.h5, project = "pbmc_alzheimer", min.cells = 3, min.features = 200)
```


(심화)[코드 5-5] 많은 수의 샘플 변환을 For 함수를 이용해 한번에 실행하기
```{r}
# 필요한 패키지 설치 TODO: string r 설명 추가?
install.packages("stringr")
library(stringr)
# results 파일에 있는 폴더들의 경로 얻기  
all_samples <- dir("../data/", full.names = TRUE)
# 경로/filtered_feature_bc_matrix.h5 
all_samples_h5 <- paste0(all_samples, "/outs/filtered_feature_bc_matrix.h5") 
# h5파일 경로와, 샘플 이름을 갖는 데이터프레임 생성
sample_manifest <- as.data.frame(all_samples_h5) %>% 
    mutate(sample_name = str_extract(all_samples_h5, "SRR\\d+")) 
# 빈 리스트 생성 
seurat_objects_list <- list() 
# for 함수를 이용해서 all_seurat_objects 리스트에 각 샘플을 seurat object 형태로 저장
for(sample in sample_manifest$sample_name){ 
    count <- Read10X_h5(glue::glue("../data/count_{sample}/outs/filtered_feature_bc_matrix.h5"), use.names = TRUE, unique.features = TRUE)
    seurat_obj <- CreateSeuratObject(counts = count, project = "pbmc_alzheimer", min.cells = 3, min.features = 200)
    seurat_objects_list[[sample]] <- seurat_obj
}
```


(참고)[코드 5-6] 슈랏 오브젝트 둘러보기 
```{r}
# 슈랏 오브젝트 출력하기
SRR13911909.h5.sobj

# 슈랏 오브젝트 메인 크기 확인하기
dim(SRR13911909.h5.sobj)            # feature (gene) x cell 크기 
colnames(SRR13911909.h5.sobj)[1:10] # cell barcode 첫 10개
rownames(SRR13911909.h5.sobj)[1:10] # feature (gene) name 첫 10개

# 메타데이터 확인하기  
SRR13911909.h5.sobj[[]] 
SRR13911909.h5.sobj@meta.data 

# RNA 에세이 확인하기 
SRR13911909.h5.sobj@assays$RNA
SRR13911909.h5.sobj[["RNA"]]

# 레이어 (카운트) 데이터 확인하기 
# 카운트 값만 포함 
SRR13911909.h5.sobj@assays$RNA@layers$counts
SRR13911909.h5.sobj[["RNA"]]@layers$counts
# 열과 행 포함 
SRR13911909.h5.sobj@assays$RNA$counts 
SRR13911909.h5.sobj[["RNA"]]$counts

# other: 슈랏 오브젝트 뒤에 @ 혹은 $을 입력 한 후 'tab'을 눌러서 어떤 데이터를 불러 올 수 있는지 확인해 보세요.
```

## 챕터 5.2 품질관리(QC) 및 필터링
[코드 5-7] SRR13911909 슈랏 오브젝트에 미토콘드리아 발현 비율 추가하기
```{r}
SRR13911909.h5.sobj[["percent.mt"]] <- PercentageFeatureSet(SRR13911909.h5.sobj, pattern = "^MT-")
```

[코드 5-8] SRR13911909 슈랏 오브젝트의 품질관리 바이올린 플롯 그리기
```{r}
VlnPlot(SRR13911909.h5.sobj, features = c("nFeature_RNA", "nCount_RNA", "percent.mt"), ncol = 3)	
```

[코드 5-9] SRR13911909 슈랏 오브젝트의 품질관리 유전자 산포도 플롯 그리기
```{r, fig.width = 6, fig.height= 6}
# 세포당 RNA 카운트와 발현된 고유 유전자 수의 상관 관계
FeatureScatter(SRR13911909.h5.sobj, feature1 = "nCount_RNA", feature2 = "nFeature_RNA")
# 세포당 RNA 카운트와 미토콘드리아 발현 비율 상관 관계
FeatureScatter(SRR13911909.h5.sobj, feature1 = "nCount_RNA", feature2 = "percent.mt")
```

[코드 5-10] SRR13911909 슈랏 오브젝트 필터링하기
```{r}
SRR13911909.h5.sobj <- subset(SRR13911909.h5.sobj, subset = nFeature_RNA > 200 & nFeature_RNA < 3500 & percent.mt < 10)
```

[코드 5-11] 필터링된 SRR13911909 슈랏 오브젝트의 품질 관리 플롯 그리기
```{r, fig.width=6, fig.height=6}
# 바이올린 플롯
VlnPlot(SRR13911909.h5.sobj, features = c("nFeature_RNA", "nCount_RNA", "percent.mt"), ncol = 3)	

# 유전자 산포도 플롯
FeatureScatter(SRR13911909.h5.sobj, feature1 = "nCount_RNA", feature2 = "nFeature_RNA")
FeatureScatter(SRR13911909.h5.sobj, feature1 = "nCount_RNA", feature2 = "percent.mt")
```

[코드 5-12] 각 샘플에 미토콘드리아 발현 비율 추가
```{r}
SRR13911909.h5.sobj[["percent.mt"]] <- PercentageFeatureSet(SRR13911909.h5.sobj, pattern = "^MT-")
SRR13911910.h5.sobj[["percent.mt"]] <- PercentageFeatureSet(SRR13911910.h5.sobj, pattern = "^MT-")
SRR13911911.h5.sobj[["percent.mt"]] <- PercentageFeatureSet(SRR13911911.h5.sobj, pattern = "^MT-")
SRR13911912.h5.sobj[["percent.mt"]] <- PercentageFeatureSet(SRR13911912.h5.sobj, pattern = "^MT-")
SRR13911913.h5.sobj[["percent.mt"]] <- PercentageFeatureSet(SRR13911913.h5.sobj, pattern = "^MT-")
SRR13911914.h5.sobj[["percent.mt"]] <- PercentageFeatureSet(SRR13911914.h5.sobj, pattern = "^MT-")
```

[코드 5-13] QC 시각화 하기 – 바이올린 플롯 
```{r}
VlnPlot(SRR13911909.h5.sobj, features = c("nFeature_RNA", "nCount_RNA", "percent.mt"), ncol = 3)
VlnPlot(SRR13911910.h5.sobj, features = c("nFeature_RNA", "nCount_RNA", "percent.mt"), ncol = 3)
VlnPlot(SRR13911911.h5.sobj, features = c("nFeature_RNA", "nCount_RNA", "percent.mt"), ncol = 3)
VlnPlot(SRR13911912.h5.sobj, features = c("nFeature_RNA", "nCount_RNA", "percent.mt"), ncol = 3)
VlnPlot(SRR13911913.h5.sobj, features = c("nFeature_RNA", "nCount_RNA", "percent.mt"), ncol = 3)
VlnPlot(SRR13911914.h5.sobj, features = c("nFeature_RNA", "nCount_RNA", "percent.mt"), ncol = 3)
```

[코드 5-14] QC 시각화 하기 – 유전자 산포도 
```{r, fig.width = 6, fig.height= 6}
# 세포당 RNA 카운트와 발현된 고유 유전자 수의 상관 관계  
FeatureScatter(SRR13911910.h5.sobj, feature1 = "nCount_RNA", feature2 = "nFeature_RNA")
# 세포당 RNA 카운트와 미토콘드리아 발현 비율 상관 관계
FeatureScatter(SRR13911910.h5.sobj, feature1 = "nCount_RNA", feature2 = "percent.mt")

FeatureScatter(SRR13911911.h5.sobj, feature1 = "nCount_RNA", feature2 = "nFeature_RNA")
FeatureScatter(SRR13911911.h5.sobj, feature1 = "nCount_RNA", feature2 = "percent.mt")
FeatureScatter(SRR13911912.h5.sobj, feature1 = "nCount_RNA", feature2 = "nFeature_RNA")
FeatureScatter(SRR13911912.h5.sobj, feature1 = "nCount_RNA", feature2 = "percent.mt")
FeatureScatter(SRR13911913.h5.sobj, feature1 = "nCount_RNA", feature2 = "nFeature_RNA")
FeatureScatter(SRR13911913.h5.sobj, feature1 = "nCount_RNA", feature2 = "percent.mt")
FeatureScatter(SRR13911914.h5.sobj, feature1 = "nCount_RNA", feature2 = "nFeature_RNA")
FeatureScatter(SRR13911914.h5.sobj, feature1 = "nCount_RNA", feature2 = "percent.mt")
```

[코드 5-15] 각 샘플들의 품질관리 플롯들을 이용해서 필터링하기 
```{r}
# 필터링 
SRR13911909.h5.sobj <- subset(SRR13911909.h5.sobj, subset = nFeature_RNA > 200 & nFeature_RNA < 3500 & percent.mt < 10)  
SRR13911910.h5.sobj <- subset(SRR13911910.h5.sobj, subset = nFeature_RNA > 200 & nFeature_RNA < 3500 & percent.mt < 10)
SRR13911911.h5.sobj <- subset(SRR13911911.h5.sobj, subset = nFeature_RNA > 200 & nFeature_RNA < 3500 & percent.mt < 10)
SRR13911912.h5.sobj <- subset(SRR13911912.h5.sobj, subset = nFeature_RNA > 200 & nFeature_RNA < 3500 & percent.mt < 10)
SRR13911913.h5.sobj <- subset(SRR13911913.h5.sobj, subset = nFeature_RNA > 200 & nFeature_RNA < 3500 & percent.mt < 10)
SRR13911914.h5.sobj <- subset(SRR13911914.h5.sobj, subset = nFeature_RNA > 200 & nFeature_RNA < 3500 & percent.mt < 10)
```

(예시) 필터링 된 데이터의 품질관리 플롯 그려보기 (삭제?)
```{r, fig.width = 10}
# 예시 - SRR13911909.h5.sobj
VlnPlot(SRR13911909.h5.sobj, features = c("nFeature_RNA", "nCount_RNA", "percent.mt"), ncol = 3)
FeatureScatter(SRR13911909.h5.sobj, feature1 = "nCount_RNA", feature2 = "percent.mt")
FeatureScatter(SRR13911909.h5.sobj, feature1 = "nCount_RNA", feature2 = "nFeature_RNA")
```

(심화) [코드 5-16] lapply를 이용하여 한번에 슈랏 오브젝트 리스트 품질관리 및 필터링하기
```{r}
seurat_objects_list <- lapply(seurat_objects_list, function(sobj) {  
    sobj <- sobj %>%  
        PercentageFeatureSet(pattern = "^MT-", col.name = "percent.mt") %>%  
        subset(subset = nFeature_RNA > 200 & nFeature_RNA < 3500 & percent.mt < 10) 
}) 
```


# 챕터 6 데이터 정규화 및 통합
## 챕터 6.1 로그정규화 이용 
[코드 6-1] 로그 정규화 실행하기
_NormalizeData()_: https://satijalab.org/seurat/reference/normalizedata 
```{r}
SRR13911909.h5.sobj_norm <- NormalizeData(SRR13911909.h5.sobj, verbose = TRUE) 
SRR13911910.h5.sobj_norm <- NormalizeData(SRR13911910.h5.sobj, verbose = FALSE)
SRR13911911.h5.sobj_norm <- NormalizeData(SRR13911911.h5.sobj, verbose = FALSE)
SRR13911912.h5.sobj_norm <- NormalizeData(SRR13911912.h5.sobj, verbose = FALSE)
SRR13911913.h5.sobj_norm <- NormalizeData(SRR13911913.h5.sobj, verbose = FALSE)
SRR13911914.h5.sobj_norm <- NormalizeData(SRR13911914.h5.sobj, verbose = FALSE)
```

[코드 6-2] 유의미한 유전자 추출하기
```{r}
SRR13911909.h5.sobj_norm <- FindVariableFeatures(SRR13911909.h5.sobj_norm, selection.method = "vst", nfeatures = 2000, verbose = TRUE)
SRR13911910.h5.sobj_norm <- FindVariableFeatures(SRR13911910.h5.sobj_norm, selection.method = "vst", nfeatures = 2000, verbose = FALSE)
SRR13911911.h5.sobj_norm <- FindVariableFeatures(SRR13911911.h5.sobj_norm, selection.method = "vst", nfeatures = 2000, verbose = FALSE)
SRR13911912.h5.sobj_norm <- FindVariableFeatures(SRR13911912.h5.sobj_norm, selection.method = "vst", nfeatures = 2000, verbose = FALSE)
SRR13911913.h5.sobj_norm <- FindVariableFeatures(SRR13911913.h5.sobj_norm, selection.method = "vst", nfeatures = 2000, verbose = FALSE)
SRR13911914.h5.sobj_norm <- FindVariableFeatures(SRR13911914.h5.sobj_norm, selection.method = "vst", nfeatures = 2000, verbose = FALSE)

# 유의미한 유전자 확인하기 예시
VariableFeatures(SRR13911909.h5.sobj_norm)
```

[코드 6-3] 스케일링 
```{r}
SRR13911909.h5.sobj_norm <- ScaleData(SRR13911909.h5.sobj_norm, verbose = TRUE) 
SRR13911910.h5.sobj_norm <- ScaleData(SRR13911910.h5.sobj_norm, verbose = FALSE)
SRR13911911.h5.sobj_norm <- ScaleData(SRR13911911.h5.sobj_norm, verbose = FALSE)
SRR13911912.h5.sobj_norm <- ScaleData(SRR13911912.h5.sobj_norm, verbose = FALSE)
SRR13911913.h5.sobj_norm <- ScaleData(SRR13911913.h5.sobj_norm, verbose = FALSE)
SRR13911914.h5.sobj_norm <- ScaleData(SRR13911914.h5.sobj_norm, verbose = FALSE)
```
[코드 6-4] 정규화된 슈랏 오브젝트들 하나의 리스트로 묶기 
```{r}
lognorm_list <- c(SRR13911909.h5.sobj_norm, SRR13911910.h5.sobj_norm, SRR13911911.h5.sobj_norm, SRR13911912.h5.sobj_norm, SRR13911913.h5.sobj_norm, SRR13911914.h5.sobj_norm)
```

(심화)[코드 6-5] 코드 6-1 부터 6-4까지를 함축한 명령어
```{r}
# 모든 샘플 정규화하고 하나의 리스트로 묶기
lognorm_list <- lapply(seurat_objects_list, function(x) {
  x <- NormalizeData(x)
  x <- FindVariableFeatures(x, selection.method = "vst", nfeatures = 2000)
  x <- ScaleData(x) 
})
```

```{r}
# raw 데이터 
SRR13911909.h5.sobj_norm[["RNA"]]$counts # 혹은 pbmc_alzheimer_Log_1@assays$RNA$counts.1

# 정규화 된 데이터 
SRR13911909.h5.sobj_norm[["RNA"]]$data

SRR13911909.h5.sobj_norm@assays$RNA@layers$data[1:5,]
SRR13911909.h5.sobj_norm@assays$RNA$data
SRR13911909.h5.sobj_norm[["RNA"]]$data[1:5,]
```

```{r}
# 2024 to demo merged without integration -> batch effect 
pbmc_alzheimer_Log_2 <- merge(SRR13911909.h5.sobj, y = c(SRR13911910.h5.sobj, SRR13911911.h5.sobj,SRR13911912.h5.sobj,SRR13911913.h5.sobj,SRR13911914.h5.sobj), add.cell.ids = c("SRR13911909", "SRR13911910", "SRR13911911", "SRR13911912", "SRR13911913", "SRR13911914"), project = "pbmc_alzheimer")


dim(pbmc_alzheimer_Log_2[["RNA"]]$counts.1) #  21423 11325
dim(pbmc_alzheimer_Log_2_joined[["RNA"]]$counts) # 24164 74134 
pbmc_alzheimer_Log_2
 
pbmc_alzheimer_Log_2_joined <- pbmc_alzheimer_Log_2
pbmc_alzheimer_Log_2_joined[["RNA"]] <- JoinLayers(pbmc_alzheimer_Log_2_joined[["RNA"]]) # all the counts into one count 

pbmc_alzheimer_Log_2_joined <- SCTransform(pbmc_alzheimer_Log_2_joined, verbose = FALSE)  # need? -> sure for the same condition

pbmc_alzheimer_Log_2_joined@meta.data <- pbmc_alzheimer_Log_2_joined@meta.data %>%
  mutate(Run = ifelse(grepl("SRR13911909_", rownames(.)), "SRR13911909", 
                              ifelse(grepl("SRR13911910_", rownames(.)), "SRR13911910",
                                     ifelse(grepl("SRR13911911_", rownames(.)), "SRR13911911",
                                            ifelse(grepl("SRR13911912_", rownames(.)), "SRR13911912",
                                                   ifelse(grepl("SRR13911913_", rownames(.)), "SRR13911913",
                                                          ifelse(grepl("SRR13911914_", rownames(.)), "SRR13911914", "NA")))))))

# manifest
manifest <- read.csv("SraRunTable.txt")
manifest <- manifest %>% # 필요한 컬럼만 추출해내기 
  select(c(Run, Age, subject_status))

pbmc_alzheimer_Log_2_joined@meta.data[c("Run", "Age", "subject_status")] <-
  manifest[match(pbmc_alzheimer_Log_2_joined$Run, manifest$Run), ]
# saveRDS(pbmc_alzheimer_Log_2_joined, "./rds/pbmc_alzheimer_Log_2_joined.rds")


pbmc_alzheimer_Log_2_joined <- RunPCA(pbmc_alzheimer_Log_2_joined, verbose = FALSE)
pbmc_alzheimer_Log_2_joined <- RunUMAP(pbmc_alzheimer_Log_2_joined, reduction = "pca", dims = 1:30, verbose = FALSE)
pbmc_alzheimer_Log_2_joined <- FindNeighbors(pbmc_alzheimer_Log_2_joined, reduction = "pca", dims = 1:30)
pbmc_alzheimer_Log_2_joined <- FindClusters(pbmc_alzheimer_Log_2_joined, resolution = 0.3)

# UMAP group by age 
DimPlot(
  pbmc_alzheimer_Log_2_joined,
  reduction = "umap",
  group.by = "Age",
  combine = FALSE, label.size = 2
)
```

## 챕터 6.2 SCTranfrom정규화 이용
[코드 6-5] SCTransform 정규화 실행하기
_SCTransform()_: https://satijalab.org/seurat/reference/sctransform 
```{r}
job({
  SRR13911909.h5.sobj_SCT <- SCTransform(SRR13911909.h5.sobj, vars.to.regress = "percent.mt", verbose = TRUE) 
  SRR13911910.h5.sobj_SCT <- SCTransform(SRR13911910.h5.sobj, vars.to.regress = "percent.mt", verbose = FALSE) 
  SRR13911911.h5.sobj_SCT <- SCTransform(SRR13911911.h5.sobj, vars.to.regress = "percent.mt", verbose = FALSE) 
  SRR13911912.h5.sobj_SCT <- SCTransform(SRR13911912.h5.sobj, vars.to.regress = "percent.mt", verbose = FALSE) 
  SRR13911913.h5.sobj_SCT <- SCTransform(SRR13911913.h5.sobj, vars.to.regress = "percent.mt", verbose = FALSE) 
  SRR13911914.h5.sobj_SCT <- SCTransform(SRR13911914.h5.sobj, vars.to.regress = "percent.mt", verbose = FALSE) 
})

# Running SCTransform on assay: RNA
# Running SCTransform on layer: counts
# vst.flavor='v2' set. Using model with fixed slope and excluding poisson genes.
# Variance stabilizing transformation of count matrix of size 20543 by 11464
# Model formula is y ~ log_umi
# Get Negative Binomial regression parameters per gene
# Using 2000 genes, 5000 cells
# Found 269 outliers - those will be ignored in fitting/regularization step
# 
# Second step: Get residuals using fitted parameters for 20543 genes
# Computing corrected count matrix for 20543 genes
# Calculating gene attributes
# Wall clock passed: Time difference of 1.036254 mins
# Determine variable features
# Regressing out percent.mt
# Centering data matrix
# Getting residuals for block 1(of 3) for counts dataset
# Getting residuals for block 2(of 3) for counts dataset
# Getting residuals for block 3(of 3) for counts dataset
# Regressing out percent.mt
# Centering data matrix
# Finished calculating residuals for counts
# Set default assay to SCT
```

[코드 6-6] 여러 개의 슈랏 오브젝트를 하나의 리스트로 묶기 
```{r}
pbmc_alzheimer_SCT.list <- list(SRR13911909.h5.sobj_SCT, SRR13911910.h5.sobj_SCT, SRR13911911.h5.sobj_SCT, SRR13911912.h5.sobj_SCT, SRR13911913.h5.sobj_SCT, SRR13911914.h5.sobj_SCT)
```

(참고)[코드 6-7] 오브젝트 저장 및 불러오기
```{r}
# 오브젝트 저장 
saveRDS(pbmc_alzheimer_SCT.list, "./rds/pbmc_alzheimer_SCT.list.rds")

# 오브젝트 불러오기 
pbmc_alzheimer_SCT.list <- readRDS("./rds/pbmc_alzheimer_SCT.list.rds")
```
(참고)[코드 6-8] 오브젝트 삭제 및 메모리 정리 
```{r}
# 불필요한 오브젝트 삭제  
rm(SRR13911909.h5.sobj_SCT) 
 
# 메모리 정리 
gc() 
```


## 챕터 6.3 데이터 통합 
[코드 6-9] SCT 에세이를 기반으로 데이터 합치기 
```{r}
# 샘플 간의 공통 유전자 찾기
features <- SelectIntegrationFeatures(object.list = pbmc_alzheimer_SCT.list, nfeatures = 3000) 
pbmc_alzheimer_SCT.list <- PrepSCTIntegration(object.list = pbmc_alzheimer_SCT.list, anchor.features = features) 

# 샘플 간의 앵커 찾기
pbmc_alzheimer_SCT.anchors <- FindIntegrationAnchors(object.list = pbmc_alzheimer_SCT.list, 
                                                     normalization.method = "SCT", 
                                                     anchor.features = features,
                                                     reduction = "cca")
# Warning: Some cell names are duplicated across objects provided. Renaming to enforce unique cell names.Finding all pairwise anchors
# 통합하기 
pbmc_alzheimer_SCT.combined <- IntegrateData(anchorset = pbmc_alzheimer_SCT.anchors, 
                                             normalization.method = "SCT") 


# saveRDS(pbmc_alzheimer_SCT.anchors, "./rds/pbmc_alzheimer_SCT.anchors.rds")
```
```{r}
# Warning: Some cell names are duplicated across objects provided. Renaming to enforce unique cell names.Finding all pairwise anchors
# Running CCA
# Merging objects
# Finding neighborhoods
# Finding anchors
# 	Found 20874 anchors
# Filtering anchors
# 	Retained 15958 anchors
# Running CCA
# Merging objects
# Finding neighborhoods
# Finding anchors
# 	Found 23676 anchors
# Filtering anchors
# 	Retained 17088 anchors
# Running CCA
# Merging objects
# Finding neighborhoods
# Finding anchors
# 	Found 21707 anchors
# Filtering anchors
# 	Retained 15388 anchors
# Running CCA
# Merging objects
# Finding neighborhoods
# Finding anchors
# 	Found 23075 anchors
# Filtering anchors
# 	Retained 16257 anchors
# Running CCA
# Merging objects
# Finding neighborhoods
# Finding anchors
# 	Found 21359 anchors
# Filtering anchors
# 	Retained 14311 anchors
# Running CCA
# Merging objects
# Finding neighborhoods
# Finding anchors
# 	Found 24938 anchors
# Filtering anchors
# 	Retained 17198 anchors
# Running CCA
# Merging objects
# Finding neighborhoods
# Finding anchors
# 	Found 23912 anchors
# Filtering anchors
# 	Retained 17390 anchors
# Running CCA
# Merging objects
# Finding neighborhoods
# Finding anchors
# 	Found 21706 anchors
# Filtering anchors
# 	Retained 15468 anchors
# Running CCA
# Merging objects
# Finding neighborhoods
# Finding anchors
# 	Found 24716 anchors
# Filtering anchors
# 	Retained 17717 anchors
# Running CCA
# Merging objects
# Finding neighborhoods
# Finding anchors
# 	Found 23991 anchors
# Filtering anchors
# 	Retained 17011 anchors
# Running CCA
# Merging objects
# Finding neighborhoods
# Finding anchors
# 	Found 27923 anchors
# Filtering anchors
# 	Retained 17655 anchors
# Running CCA
# Merging objects
# Finding neighborhoods
# Finding anchors
# 	Found 25301 anchors
# Filtering anchors
# 	Retained 15261 anchors
# Running CCA
# Merging objects
# Finding neighborhoods
# Finding anchors
# 	Found 29464 anchors
# Filtering anchors
# 	Retained 18067 anchors
# Running CCA
# Merging objects
# Finding neighborhoods
# Finding anchors
# 	Found 29590 anchors
# Filtering anchors
# 	Retained 18058 anchors
# Running CCA
# Merging objects
# Finding neighborhoods
# Finding anchors
# 	Found 29331 anchors
# Filtering anchors
# 	Retained 17480 anchors
# [1] 1
# Warning: Different cells and/or features from existing assay SCTWarning: Layer counts isn't present in the assay object; returning NULL[1] 2
# Warning: Different cells and/or features from existing assay SCTWarning: Layer counts isn't present in the assay object; returning NULL[1] 3
# Warning: Different cells and/or features from existing assay SCTWarning: Layer counts isn't present in the assay object; returning NULL[1] 4
# Warning: Different cells and/or features from existing assay SCTWarning: Layer counts isn't present in the assay object; returning NULL[1] 5
# Warning: Different cells and/or features from existing assay SCTWarning: Layer counts isn't present in the assay object; returning NULL[1] 6
# Warning: Different cells and/or features from existing assay SCTWarning: Layer counts isn't present in the assay object; returning NULLMerging dataset 2 into 1
# Extracting anchors for merged samples
# Finding integration vectors
# Finding integration vector weights
# 0%   10   20   30   40   50   60   70   80   90   100%
# [----|----|----|----|----|----|----|----|----|----|
# **************************************************|
# Integrating data
# Warning: Layer counts isn't present in the assay object; returning NULLMerging dataset 3 into 6
# Extracting anchors for merged samples
# Finding integration vectors
# Finding integration vector weights
# 0%   10   20   30   40   50   60   70   80   90   100%
# [----|----|----|----|----|----|----|----|----|----|
# **************************************************|
# Integrating data
# Warning: Layer counts isn't present in the assay object; returning NULLMerging dataset 5 into 6 3
# Extracting anchors for merged samples
# Finding integration vectors
# Finding integration vector weights
# 0%   10   20   30   40   50   60   70   80   90   100%
# [----|----|----|----|----|----|----|----|----|----|
# **************************************************|
# Integrating data
# Warning: Layer counts isn't present in the assay object; returning NULLMerging dataset 1 2 into 6 3 5
# Extracting anchors for merged samples
# Finding integration vectors
# Finding integration vector weights
# 0%   10   20   30   40   50   60   70   80   90   100%
# [----|----|----|----|----|----|----|----|----|----|
# **************************************************|
# Integrating data
# Warning: Layer counts isn't present in the assay object; returning NULLMerging dataset 4 into 6 3 5 1 2
# Extracting anchors for merged samples
# Finding integration vectors
# Finding integration vector weights
# 0%   10   20   30   40   50   60   70   80   90   100%
# [----|----|----|----|----|----|----|----|----|----|
# **************************************************|
# Integrating data
# Warning: Layer counts isn't present in the assay object; returning NULLWarning: sparse->dense coercion: allocating vector of size 1.7 GiBWarning: Assay integrated changing from Assay to SCTAssayWarning: Layer counts isn't present in the assay object; returning NULLWarning: Different cells and/or features from existing assay SCT
```


(참고) [코드 6-10] 메모리 할당량 늘리기 
```{r}
# 필요 없는 오브젝트들 삭제 
rm(count_SRR13911909.h5, count_SRR13911910.h5, count_SRR13911911.h5, count_SRR13911912.h5, count_SRR13911913.h5, count_SRR13911914.h5)
rm(SRR13911909.h5.sobj, SRR13911910.h5.sobj, SRR13911911.h5.sobj, SRR13911912.h5.sobj, SRR13911913.h5.sobj, SRR13911914.h5.sobj)
rm(SRR13911909.h5.sobj_SCT, SRR13911910.h5.sobj_SCT, SRR13911911.h5.sobj_SCT, SRR13911912.h5.sobj_SCT, SRR13911913.h5.sobj_SCT, SRR13911914.h5.sobj_SCT)

# R 메모리 할당량 늘리기
Install.packages("usethis")
library(usethis) 
usethis::edit_r_environ()
# 위의 코드로 R 환경 설정 파일 ('.Renviron') 이 실행되면 'R_MAX_VSIZE=100Gb' 작성 후 저장하기
```

[코드 6-11]
```{r}
# future 패키지 설치 및 불러오기  
install.packages("future") 
library(future) 

# 병렬 처리 전략 설정  
plan("multicore", workders = 8) 

# 병렬 작업 중 전역 환경에서 사용할 수 있는 메모리의 최대 크기 제한.  
options(future.globals.maxSize = 8000 * 1024^2 ) 
```
[코드 6-12] 로그 정규화환 샘플들을 하나로 통합하기? error
```{r}

```

```{r}
# window specific
memory.limit()
memory.size()

# others 
#  1 GB = 1,024 × 1,024 kB = 1,048,576 kB
system("grep MemTotal /proc/meminfo") # 528,241,728kB ~ 503.GB
system("grep MemFree /proc/meminfo")

Sys.getenv()
grepl("R_MAX_VSIZE",Sys.getenv())


# error: Error in getGlobalAndPackes(expr, envir = envir, globals = globals)
# try [1]
options(future.globals.maxSize = 50000 * 1024^2) 

# try [2] 
library(future)
plan("multiprocess", workers = 10)


# error: vector memory exhausted 
# try [1] 
Sys.setenv('R_MAX_VSIZE'=32000000000) # set the memory limit to ~ 30 GB 


# try [2]
library(usethis) 
usethis::edit_r_environ() 
# add R_MAX_VSIZE=100Gb when the screen opens using 'usethis::edit_r_environ() '

# try [3] : rm unnecessary things 
rm(SRR13911909.h5.sobj)
rm(SRR13911909.h5.sobj_SCT)
```

(예시) 앵커 들여다보기
TODO: 확인
```{r}
# 앵커 확인 
pbmc_alzheimer_SCT.anchors

# 통합된 데이터 들여다보기  
identical(pbmc_alzheimer_SCT.combined[["integrated"]]$data, pbmc_alzheimer_SCT.combined[["integrated"]]$scale.data) # FALSE
dim(pbmc_alzheimer_SCT.combined[["integrated"]]$data) # 3000 74134
dim(pbmc_alzheimer_SCT.combined[["integrated"]]$scale.data) # 3000 74134

pbmc_alzheimer_SCT.combined[["integrated"]]$data[1:5, 1:5]
pbmc_alzheimer_SCT.combined[["integrated"]]$scale.data[1:5, 1:5]
```

```{r}
merged_sobj <- merge(SRR13911909.h5.sobj_norm, 
                     y = c(SRR13911910.h5.sobj_norm, SRR13911911.h5.sobj_norm, 
                           SRR13911912.h5.sobj_norm, SRR13911913.h5.sobj_norm, 
                           SRR13911914.h5.sobj_norm))

merged_sobj <- JoinLayers(merged_sobj) 
merged_sobj <- RunPCA(merged_sobj) 

merged_sobj_integrated <- IntegrateLayers(
  object = merged_sobj, 
  method = CCAIntegration,
  orig.reduction = "pca", 
  new.reduction = "integrated.cca",
  verbose = FALSE
)
# Error in UseMethod(generic = "Assays", object = object) : 
#   no applicable method for 'Assays' applied to an object of class "NULL"

merged_sobj_integrated <- IntegrateLayers(
  object = merged_sobj, method = HarmonyIntegration,
  orig.reduction = "pca", new.reduction = "harmony",
  verbose = FALSE
)
# Error in names(groups) <- "group" : attempt to set an attribute on NULL
```


# 챕터 7 차원 축소 및 클러스터링
SCTransform 정규화 및 CCA 통합 된 pbmc_alzheimer_SCT.combined로 이어서 진행합니다. 
  - _RunPCA()_: PCA on the scaled data
  - _RunUMAP()_
  - _FindNeighbors()_
  - _FindClusters()_ 

[코드 7-1] PCA 차원 축소하기
```{r}
pbmc_alzheimer_SCT.combined <- RunPCA(pbmc_alzheimer_SCT.combined, verbose = TRUE)
```

[코드 7-2] PCA 주성분 수 고르기
```{r, fig.height = 10}
# 엘보우 플롯 (주성분 50개)  
ElbowPlot(pbmc_alzheimer_SCT.combined, ndims = 530, reduction = 'pca')
```

[코드 7-3] 주성분별 히트맵 그리기
```{r, fig.height = 10}
# 주성분 1부터 주성분 6까지의 히트맵  
DimHeatmap(pbmc_alzheimer_SCT.combined, dims = 1:6, cells = 500, balanced = TRUE) 
```

```{R}
# testing? 
# Idents(pbmc_alzheimer_SCT.combined) <-  "orig.ident"
# pdf("./results/pca_results.pdf", width = 10)
print(pbmc_alzheimer_SCT.combined[["pca"]], dims = 1:10, nfeatures = 5)
DimPlot(pbmc_alzheimer_SCT.combined, reduction = "pca") + NoLegend() # 나중에 clustering 한 후에, 해당 색칠해서 확인해보면 어느 pc dimension이 어떤 cell type을 구분할 수 있는지도 보인다. 
ElbowPlot(pbmc_alzheimer_SCT.combined, ndims = 30, reduction = 'pca') # -> 20 dimension 사용 예정
DimHeatmap(pbmc_alzheimer_SCT.combined, dims = 25:30, cells = 500, balanced = TRUE)
# dev.off()
```

[코드 7-4] TSNE 계산하기
```{r}
# TSNE
pbmc_alzheimer_SCT.combined <- RunTSNE(pbmc_alzheimer_SCT.combined, reduction = "pca", dims = 1:30, verbose = FALSE)
```

[코드 7-5] UMAP 계산하기
```{r}
# UMAP
pbmc_alzheimer_SCT.combined <- RunUMAP(pbmc_alzheimer_SCT.combined, reduction = "pca", dims = 1:30, verbose = FALSE)
```

[코드 7-5] 클러스터링
```{r}
pbmc_alzheimer_SCT.combined <- FindNeighbors(pbmc_alzheimer_SCT.combined, reduction = "pca", dims = 1:30)
pbmc_alzheimer_SCT.combined <- FindClusters(pbmc_alzheimer_SCT.combined, resolution = c(0.1,0.3, 0.5))
```

```{r}
# saveRDS(pbmc_alzheimer_SCT.combined, "./rds/pbmc_alzheimer_SCT.combined_UMAP.rds")
```


(심화)[코드 7-6] 차원축소 및 클러스터링 한번에 진행하기 
[코드 7-1]부터 [코드 7-5]까지 한번에 실행하는 코드입니다. 
```{r}
pbmc_alzheimer_SCT.combined <- RunPCA(pbmc_alzheimer_SCT.combined, verbose = FALSE) %>%
  RunUMAP(., reduction = "pca", dims = 1:30, verbose = FALSE) %>%
  FindNeighbors(., reduction = "pca", dims = 1:30) %>% 
  FindClusters(., resolution = c(0.1, 0.3, 0.5))
```

[코드 7-7] UMAP 시각화 
```{r, fig.width = 15}
pdf("./results/UMAP_integrated_snn_res.0.1_0.3_0.5.pdf", width = 10)
Idents(pbmc_alzheimer_SCT.combined) <- "integrated_snn_res.0.1"
DimPlot(pbmc_alzheimer_SCT.combined, label = T, label.size = 7, reduction = "umap")

Idents(pbmc_alzheimer_SCT.combined) <- "integrated_snn_res.0.3"
DimPlot(pbmc_alzheimer_SCT.combined, label = T, label.size = 7, reduction = "umap")

Idents(pbmc_alzheimer_SCT.combined) <- "integrated_snn_res.0.5"
DimPlot(pbmc_alzheimer_SCT.combined, label = T, label.size = 7, reduction = "umap")
dev.off()
```

[코드 7-8] TSNE 시각화 
```{r}
pdf("./results/TSNE_integrated_snn_res.0.1_0.3_0.5.pdf", width = 10)
Idents(pbmc_alzheimer_SCT.combined) <- "integrated_snn_res.0.1"
DimPlot(pbmc_alzheimer_SCT.combined, label = T, label.size = 7, reduction = "tsne")

Idents(pbmc_alzheimer_SCT.combined) <- "integrated_snn_res.0.3"
DimPlot(pbmc_alzheimer_SCT.combined, label = T, label.size = 7, reduction = "tsne")

Idents(pbmc_alzheimer_SCT.combined) <- "integrated_snn_res.0.5"
DimPlot(pbmc_alzheimer_SCT.combined, label = T, label.size = 7, reduction = "tsne")
dev.off()
```


```{r}
# saveRDS(pbmc_alzheimer_SCT.combined, "./rds/pbmc_alzheimer_SCT.combined_2_clustered_2024.rds")
# pbmc_alzheimer_SCT.combined <- readRDS("./rds/00.Archive/pbmc_alzheimer_SCT.combinded_2_clustered_2024.rds")
```


# 챕터 8 배치 효과 교정 
```{r}
# test 1
lognorm_list_processed <- lapply(lognorm_list, function(sobj) {  
    sobj <- sobj %>%  
      SCTransform(.,verbose = FALSE) %>%
      RunPCA(., verbose = FALSE) %>%
      RunUMAP(., reduction = "pca", dims = 1:20, verbose = FALSE) %>%
      FindNeighbors(., reduction = "pca", dims = 1:20) %>% 
      FindClusters(., resolution = c(0.3)) # option
}) 
# merge them
lognorm_list_processed_merged <- scCustomixe::Merge_Seurat_List(
  lognorm_list_processed,
  add.cell.ids = NULL,
  merge.data = TRUE
)
# draw dimplot 


# test 2 
# merge them 
# then run dimension reduction 
```

[코드 8-1] 배치 효과 교정 없이 슈랏 오브젝트들 합치기
```{r}
SCT_merged <- merge(SRR13911909.h5.sobj_SCT,  y = c(SRR13911910.h5.sobj_SCT,SRR13911911.h5.sobj_SCT, SRR13911912.h5.sobj_SCT,SRR13911913.h5.sobj_SCT,SRR13911914.h5.sobj_SCT), project = "pbmc_alzheimer")
```

(참고)[코드 8-2] 배치 효과 교정 없이 슈랏 오브젝트들 합치기 - 샘플 이름 이용 
```{r}
SCT_merged_name <- merge(SRR13911909.h5.sobj_SCT, y = c(SRR13911910.h5.sobj_SCT, SRR13911911.h5.sobj_SCT,SRR13911912.h5.sobj_SCT,SRR13911913.h5.sobj_SCT,SRR13911914.h5.sobj_SCT), add.cell.ids = c("SRR13911909", "SRR13911910", "SRR13911911", "SRR13911912", "SRR13911913", "SRR13911914"), project = "pbmc_alzheimer")
```

[코드 8-3] 차원 축소 및 클러스터링 - 배치 효과 교정 없이 합쳐진 슈랏 오브젝트
```{r}
# [코드 6-7] 에서 구한 공통 유전자 3000개 이용 
VariableFeatures(SCT_merged) <- features # TODO: 다르게 해야하나..??

# 차원 축소 및 클러스터링 
SCT_merged <- RunPCA(SCT_merged, verbose = FALSE) %>%
  RunUMAP(., reduction = "pca", dims = 1:20, verbose = FALSE) %>%
  RunTSNE(., reduction = "pca", dims = 1:20, verbose = FALSE) %>%
  FindNeighbors(., reduction = "pca", dims = 1:20) %>% 
  FindClusters(., resolution = c(0.1, 0.3, 0.5))

# saveRDS(SCT_merged, "./rds/SCT_merged.rds") # 2024.05.10
```

[코드 8-3] 메타 데이터 추가하기 - 배치 효과 교정 없이 합쳐진 슈랏 오브젝트
```{r}
# 메타 데이터에 샘플 이름 추가하기, 'Run' 컬럼 
SCT_merged@meta.data <- SCT_merged@meta.data %>%
  mutate(Run = ifelse(grepl("_1", rownames(.)), "SRR13911909", 
                              ifelse(grepl("_2", rownames(.)), "SRR13911910",
                                     ifelse(grepl("_3", rownames(.)), "SRR13911911",
                                            ifelse(grepl("_4", rownames(.)), "SRR13911912",
                                                   ifelse(grepl("_5", rownames(.)), "SRR13911913",
                                                          ifelse(grepl("_6", rownames(.)), "SRR13911914", "NA")))))))

# 샘플 메타데이터 읽기 
manifest <- read.csv("SraRunTable.txt")
manifest <- manifest %>% 
  select(c(Run, Age, subject_status)) # 필요한 컬럼만 추출해내기  

# 샘플 메타데이터 추가하기
SCT_merged@meta.data[c("Run", "Age", "subject_status")] <-
  manifest[match(SCT_merged$Run, manifest$Run), ]
```

[코드 8-3] 메타 데이터 추가하기 - 배치 효과 교정된 슈랏 오브젝트
```{r}
# 메타 데이터에 샘플 이름 추가하기, 'Run' 컬럼 
pbmc_alzheimer_SCT.combined@meta.data <- pbmc_alzheimer_SCT.combined@meta.data %>%
  mutate(Run = ifelse(grepl("_1", rownames(.)), "SRR13911909", 
                              ifelse(grepl("_2", rownames(.)), "SRR13911910",
                                     ifelse(grepl("_3", rownames(.)), "SRR13911911",
                                            ifelse(grepl("_4", rownames(.)), "SRR13911912",
                                                   ifelse(grepl("_5", rownames(.)), "SRR13911913",
                                                          ifelse(grepl("_6", rownames(.)), "SRR13911914", "NA")))))))

# 샘플 메타데이터 읽고추가하기 
manifest <- read.csv("SraRunTable.txt")
manifest <- manifest %>% 
  select(c(Run, Age, subject_status)) # 필요한 컬럼만 추출해내기  

# 샘플 메타데이터 추가하기
pbmc_alzheimer_SCT.combined@meta.data[c("Run", "Age", "subject_status")] <-
  manifest[match(pbmc_alzheimer_SCT.combined$Run, manifest$Run), ]
```

[코드 8-4] 배치효과 확인 - 배치 효과 교정 없이 합쳐진 슈랏 오브젝트
Q. 같은 feature를 사용해서 그런지 배치 효과가 없다. Log normalized 로 했을때는 배치가 좀 보였던것 같은데 어떡하지 
```{r}
pdf("./results/SCT_merged_배치효과확인.pdf", width = 10)
Idents(SCT_merged) <-  SCT_merged@meta.data[["Run"]]
DimPlot(SCT_merged, label = F, label.size = 7, reduction = "umap")
DimPlot(SCT_merged, label = F, label.size = 7, reduction = "tsne")

Idents(SCT_merged) <-  SCT_merged@meta.data[["Run"]]
DimPlot(SCT_merged, label = F, label.size = 7, reduction = "umap", split.by = "Run")
DimPlot(SCT_merged, label = F, label.size = 7, reduction = "tsne", split.by = "Run")

Idents(SCT_merged) <-  SCT_merged@meta.data[["Age"]]
DimPlot(SCT_merged, label = F, label.size = 7, reduction = "umap")
DimPlot(SCT_merged, label = F, label.size = 7, reduction = "tsne")

Idents(SCT_merged) <-  SCT_merged@meta.data[["Age"]]
DimPlot(SCT_merged, label = F, label.size = 7, reduction = "umap", split.by = "Age")
DimPlot(SCT_merged, label = F, label.size = 7, reduction = "tsne", split.by = "Age")
dev.off()
```

[코드 8-4] 배치효과 확인 - CCA로 통합 된 슈랏 오브젝트
```{r}
# pdf("./results/pbmc_alzheimer_SCT.combined_배치효과확인.pdf", width = 10)
Idents(pbmc_alzheimer_SCT.combined) <-  pbmc_alzheimer_SCT.combined@meta.data[["Run"]]
DimPlot(pbmc_alzheimer_SCT.combined, label = F, label.size = 7, reduction = "umap")
DimPlot(pbmc_alzheimer_SCT.combined, label = F, label.size = 7, reduction = "tsne")

Idents(pbmc_alzheimer_SCT.combined) <-  pbmc_alzheimer_SCT.combined@meta.data[["Run"]]
DimPlot(pbmc_alzheimer_SCT.combined, label = F, label.size = 7, reduction = "umap", split.by = "Run")
DimPlot(pbmc_alzheimer_SCT.combined, label = F, label.size = 7, reduction = "tsne", split.by = "Run")

Idents(pbmc_alzheimer_SCT.combined) <-  pbmc_alzheimer_SCT.combined@meta.data[["Age"]]
DimPlot(pbmc_alzheimer_SCT.combined, label = F, label.size = 7, reduction = "umap")
DimPlot(pbmc_alzheimer_SCT.combined, label = F, label.size = 7, reduction = "tsne")


Idents(pbmc_alzheimer_SCT.combined) <-  pbmc_alzheimer_SCT.combined@meta.data[["Age"]]
DimPlot(pbmc_alzheimer_SCT.combined, label = F, label.size = 7, reduction = "umap", split.by = "Age")
DimPlot(pbmc_alzheimer_SCT.combined, label = F, label.size = 7, reduction = "tsne", split.by = "Age")
# dev.off()
```

```{r}
# only integrated PC values are exist not the count dataset 
dim(pbmc_alzheimer_SCT.combined@reductions$integrated.cca@cell.embeddings)
pbmc_alzheimer_SCT.combined@reductions$integrated.cca@feature.loadings

pbmc_alzheimer_SCT.combined@assays$integrated@data[1:10, 1:10] # only 2000 features from SCT normalized
pbmc_alzheimer_SCT.combined@assays$integrated@scale.data[1:10, 1:10] 

summary(pbmc_alzheimer_SCT.combined@assays$integrated@scale.data[1:10, 1:10])
summary(pbmc_alzheimer_SCT.combined@assays$integrated@data[1:10, 1:10])

pbmc_alzheimer_SCT.combined@assays$SCT
```

```{r}
#2024.02.01 try other integration on SCT
dim(pbmc_alzheimer_SCT.combined@reductions$integrated.cca@cell.embeddings)
# RNA - counts, data, scaled.data
# SCT - counts, data, scaled.data
# Integrated - data, scaled.data

dim(pbmc_alzheimer_SCT.combined@assays$RNA$counts) # 24164, 74134
dim(pbmc_alzheimer_SCT.combined@assays$SCT@counts) # 21737 74134
dim(pbmc_alzheimer_SCT.combined@assays$integrated$data) # 2000, 74134
dim(pbmc_alzheimer_SCT.combined@assays$integrated$scale.data) # 2000, 74134
identical(pbmc_alzheimer_SCT.combined@assays$integrated$data, pbmc_alzheimer_SCT.combined@assays$integrated$scale.data) # FALSE

pbmc_alzheimer_SCT.combined@assays$SCT@counts[1:5,1:5]
pbmc_alzheimer_SCT.combined@assays$integrated$data[1:5,1:5]
pbmc_alzheimer_SCT.combined@assays$integrated$scale.data[1:5,1:5]
dim(pbmc_alzheimer_SCT.combined@assays$SCT@scale.data) # 2000, 74134
```

[코드 8-4] Harmony 방법을 이용한 배치 효과 교정 및 데이터 통합  
```{r}
# memory.limit() # Inf - window specific
# options(future.globals.maxSize = 3e+09)
# memory.limit(size = NA)
# 데이터 복사 
obj_SCT <- pbmc_alzheimer_SCT.combined

# Harmony 통합 
obj_SCT <- IntegrateLayers(  
  object = obj_SCT,
  method = HarmonyIntegration,          # 방법 변경 가능 
  normalization.method = "SCT", 
  new.reduction = "integrated.harmony", # 새로운 차원축소 데이터 이름 
  verbose = F
)

# Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) : 
#   contrasts can be applied only to factors with 2 or more levels
#  Seurat_5.1.0
Layers(obj_SCT)


# test 
IntegrateLayers( # this works 
  object = obj_SCT, method = RPCAIntegration,
  orig.reduction = "pca", new.reduction = "integrated.rpca",
  verbose = FALSE
)
```

[코드 8-5] 배치효과 확인 - Harmony로 통합 된 슈랏 오브젝트  
```{r}
# 클러스터링 및 UMAP 계산하기 
obj_SCT <- FindNeighbors(obj_SCT, reduction = "integrated.harmony", dims = 1:30)
# obj_SCT <- FindClusters(obj_SCT, resolution = 0.3, cluster.name = "harmony_clusters")
# Error in FindClusters.Seurat(obj_SCT, resolution = 0.3, cluster.name = "harmony_clusters") : 
  # Provided graph.name not present in Seurat object
obj_SCT <- RunUMAP(obj_SCT, reduction = "integrated.harmony", dims = 1:30, reduction.name = "umap.sct.harmony")

# saveRDS(obj_SCT, "./rds/obj_SCT.rds")  
# pdf("./results/UMAP_SCT_harmony.pdf")
DimPlot(
  obj_SCT,
  reduction = "umap.sct.harmony",
  group.by = c("Run"),
  combine = FALSE, label.size = 2
)
# dev.off()
```

```{r}
# obj_SCT[["SCT"]] <- JoinLayers(obj_SCT[["SCT"]]) # 이걸 합치려면 
obj_SCT[["RNA"]]
obj_SCT@assays$RNA
obj_SCT@assays$SCT

obj_SCT[["SCT"]]

class(obj_SCT)
class(obj_SCT[["RNA"]])
class(obj_SCT[["SCT"]])

JoinLayers(obj_SCT)

dim(obj_SCT[["SCT"]]$scale.data)
identical(pbmc_alzheimer_SCT.combined[["SCT"]]$scale.data, obj_SCT[["SCT"]]$scale.data) # TRUE
identical(pbmc_alzheimer_SCT.combined@assays$SCT$counts, obj_SCT@assays$SCT$counts) # TRUE
```

```{r}

```


##Log normalization 
```{r}
obj <- pbmc_alzheimer_SCT.combined
DefaultAssay(obj) <- "RNA"
obj <- NormalizeData(obj)
obj <- FindVariableFeatures(obj)
obj <- ScaleData(obj)
obj <- RunPCA(obj) # PC 50 까지 계싼

obj <- IntegrateLayers(object = obj, method = CCAIntegration, orig.reduction = "pca", new.reduction = "integrated.cca")
# saveRDS(obj, "./rds/RNA_CCA_test.rds")
obj <- readRDS("./rds/RNA_CCA_test.rds")


# 'Run' = 샘플 이름 추가하기 
obj@meta.data <- obj@meta.data %>%
  mutate(Run = ifelse(grepl("_1", rownames(.)), "SRR13911909", 
                              ifelse(grepl("_2", rownames(.)), "SRR13911910",
                                     ifelse(grepl("_3", rownames(.)), "SRR13911911",
                                            ifelse(grepl("_4", rownames(.)), "SRR13911912",
                                                   ifelse(grepl("_5", rownames(.)), "SRR13911913",
                                                          ifelse(grepl("_6", rownames(.)), "SRR13911914", "NA")))))))

# manifest
manifest <- read.csv("../singleCell_practice/SraRunTable.txt")
manifest <- manifest %>% # 필요한 컬럼만 추출해내기 
  select(c(Run, Age, subject_status))

obj@meta.data[c("Run", "Age", "subject_status")] <-
  manifest[match(obj$Run, manifest$Run), ]
```

IntegrateLayers(
  object,
  method,
  orig.reduction = "pca",
  assay = NULL,
  features = NULL,
  layers = NULL,
  scale.layer = "scale.data",
  ...
)

IntegrateLayers() 함수는 PCA 와 scaled.data를 이용합니다. 
dim(pbmc_alzheimer_SCT.combined@assays$RNA$scale.data) # 2000, 74134

```{r}
obj <- FindNeighbors(obj, reduction = "integrated.cca", dims = 1:30)
obj <- FindClusters(obj, resolution = 2, cluster.name = "cca_clusters")
obj <- RunUMAP(obj, reduction = "integrated.cca", dims = 1:30, reduction.name = "umap.rna.cca")

DimPlot(
  obj,
  reduction = "umap.rna.cca",
  group.by = c("Age"),
  combine = FALSE, label.size = 2
)

DimPlot(
  obj,
  reduction = "umap",
  group.by = c("Age"),
  combine = FALSE, label.size = 2
)


DimPlot(
  obj,
  reduction = "integrated",
  group.by = c("Age"),
  combine = FALSE, label.size = 2
)

```

Once integrative analysis is complete, you can rejoin the layers - which collapses the individual datasets together and recreates the original counts and data layers. You will need to do this before performing any differential expression analysis. However, you can always resplit the layers in case you would like to reperform integrative analysis.
https://satijalab.org/seurat/articles/seurat5_integration 

UMAP 상에서 integration 이 된것 같으면 JoinLayers() 함수를 실행해서 실제 카운트를 합쳐 새로운 counts 와 data 레이어를 만들어 낼 수 있습니다. 

```{r}
DefaultAssay(obj) <- "RNA" # integrated didn't work for IntegrateLayers, SCT also doesn't work 
obj[["RNA"]] <- JoinLayers(obj[["RNA"]])
obj[["RNA"]]

pbmc_alzheimer_SCT.combined
obj
pbmc_alzheimer_SCT.combined[["RNA"]]
obj[["RNA"]]

identical(pbmc_alzheimer_SCT.combined[["RNA"]]$scale.data, obj[["RNA"]]$scale.data) # TRUE
obj[["RNA"]]$data # 24164 x 74134
obj[["RNA"]]$count # 24164 x 74134
```


# 9 Annotation
## 9.1 세포 특정 마커 이용

[코드 9-1] 각 클러스터마다 마커 찾기 
```{r}
# 각 클러스터의 유전자 마커 찾기
DefaultAssay(pbmc_alzheimer_SCT.combined) <- "integrated"
Idents(pbmc_alzheimer_SCT.combined) <- "integrated_snn_res.0.3"
pbmc_alzheimer_SCT.combined <- PrepSCTFindMarkers(object = pbmc_alzheimer_SCT.combined)
markers <- FindAllMarkers(pbmc_alzheimer_SCT.combined , only.pos = TRUE)
# markers <- readRDS("./rds/00.Archive/markers_0.3.rds")
# saveRDS(markers, "./rds/markers_0.3.rds")

# 각 클러스터의 유전자 마커들 중 log2FC 값이 1 이상인 마커 추출하기  
markers_log2FC_1 <- markers %>%
    group_by(cluster) %>%
    dplyr::filter(avg_log2FC > 1)

# 각 클러스터별 top 20개 마커 추출하기  
markers %>%
    group_by(cluster) %>%
    dplyr::filter(avg_log2FC > 1) %>%
    slice_head(n = 20) %>%
    ungroup() -> top20
```

[코드 9-2] 클러스터 0 의 탑 20 유전자 마커 확인하기
```{r}
top20 %>%
  filter(cluster == 0) %>%    # 클러스터가 0인 열 
  arrange(-avg_log2FC) %>%    # avg_log2FC를 기준으로 내림차순 
  pull(gene)                  # 유전자 행만 추출하기
```


[코드 9-3] 알려진 마커들을 이용해서 세포 유형 주석 달기 
```{r}
# 논문에서 주어진 세포 유형 별 마커들 
paper_markers <- list(
  B_cell = c("CD19", "MS4A1"),
  HSC = c("NCOR2", "NKX3-1", "HLX", "PRNP"),
  Monocyte = c("CLEC12A", "MS4A6A", "ZFP36L2"),
  NK_cell = c("GNLY", "GZMB", "SAMD3", "DOCK2"),
  CD4_T_cell = c("CD4", "CD3D", "CD3E", "CD3G"),
  CD8_T_cell = c("CD8A", "CD8B", "CD3D", "CD3E", "CD3G")
)

# 각 클러스터의 세포 유형 점수 구하기 
results <- list()

# 각 클러스터마다 반복 
for (cluster_n in unique(markers$cluster)){
  cluster_markers <- markers %>%
    filter(cluster == cluster_n)
  
  # 각 세포유형 마커들 중 매칭된 갯수 비율 계산  
  total_genes <- length(cluster_markers$gene)
  match_counts <- sapply(paper_markers, function(x) sum(x %in% cluster_markers$gene)/length(x))
  
  # 리스트로 정리 
  cluster_name <- paste("Cluster", cluster_n)
  results[[cluster_name]] <- match_counts
}

# 리스트들을 하나의 매트릭스로 만들기 
results_matrix <- t(sapply(results, unlist))
```

[코드 9-4] 각 세포의 세포 유형을 파악하고 슈랏 오브젝트에 추가하기 
```{r}
# 세포 유형 결정 함수
determine_cell_type <- function(cluster_scores) {
  if (all(cluster_scores == 0)) {
    return('unknown')
  } else {
    return(names(which.max(cluster_scores)))
  }
}

# 결과 매트릭스를 클러스터별로 세포 유형으로 변환
cluster_cell_types <- apply(results_matrix, 1, determine_cell_type)

# Seurat 객체에서 각 세포의 클러스터 정보를 가져옴
cluster_info <- pbmc_alzheimer_SCT.combined@meta.data$integrated_snn_res.0.3

# 각 세포에 세포 유형 할당
cell_types <- sapply(cluster_info, function(cluster) {
  cluster_name <- paste("Cluster", cluster)
  cluster_cell_types[[cluster_name]]
})

# Seurat 객체에 세포 유형 메타데이터 추가
pbmc_alzheimer_SCT.combined <- AddMetaData(pbmc_alzheimer_SCT.combined, metadata = cell_types, col.name = 'cell_type')

# 결과 확인
head(pbmc_alzheimer_SCT.combined@meta.data)
```


## 9.2 Seurat 참조 맵핑 (reference mapping) 이용하기 

먼저 참조 데이터를 다운로드 받아줍니다. 저희는 Seurat 에서 제공하는 말초 혈액 세포 참조데이터를 이용하겠습니다. https://zenodo.org/records/7779017#.ZCMojezMJqs 에서 직접 다운을 받거나 다음과 같이 R 코드로 다운받을 수 있습니다. 

[코드 9-5] 참조 데이터 Seurat 오브젝트 다운로드 
```{r}
# 다운받을 데이터의 URL 
url <- "https://zenodo.org/records/7779017/files/pbmc_multimodal_2023.rds?download=1"

# 파일 이름과, 저장 위치 정한 후 데이터 다운로드 받기 
file_name <- "pbmc_multimodal_2023.rds"
file_path <- "../data/"
download.file(url, paste(file_path, file_name, sep = ""), mode = "wb")

# 데이터 읽기 
pbmc_multimodal_2023 <- readRDS("../data/pbmc_multimodal_2023.rds")
```


_FindTransferAnchors()_ 을 이용해서 참조데이터와 우리 데이터의 공통된 지점인 anchors을 찾을 수 있으며,
추후, 해당 anchors와 _TransferData_ 함수를 이용해서 참조오브젝트의 데이터를 저희의 오브젝트에 옮길 수 있습니다. 

[코드 9-6] 참조 데이터를 이용한 세포유형 맵핑
```{r}
# 참조 데이터와의 앵커 찾기 
anchor <- FindTransferAnchors(
	reference = pbmc_multimodal_2023,
	query = pbmc_alzheimer_SCT.combined, # Pearson residuals 
	reference.assay = "SCT",
	reference.reduction = "spca",
	query.assay = "integrated",
	normalization.method = "SCT",
	dims = 1:50
)

# 앵커를 이용한 세포유형 매핑 
pbmc_alzheimer_SCT.combined <- MapQuery(
	anchorset = anchor,
	query = pbmc_alzheimer_SCT.combined,
	reference = reference,
	refdata = list(celltype.l1 = "celltype.l1", celltype.l2 = "celltype.l2"),
	reduction.model = "wnn.umap"
)


# 시각화 
## 레벨 1 (celltype.l1)
DimPlot(pbmc_alzheimer_SCT.combined, reduction = "ref.umap", group.by = "predicted.celltype.l1", label = T)
DimPlot(pbmc_alzheimer_SCT.combined, reduction = "umap", group.by = "predicted.celltype.l1", label = T)

## 레벨 2 (celltype.l2)
DimPlot(pbmc_alzheimer_SCT.combined, reduction = "ref.umap", group.by = "predicted.celltype.l2", label = T)
DimPlot(pbmc_alzheimer_SCT.combined, reduction = "umap", group.by = "predicted.celltype.l2", label = T)
```

## 9.3 외부 프로그램 이용 
  - Azimuth 
  - SingleR
  - scType
  - scanVI


### SingleR
MonacoImmuneData는 벌크 RNA 시퀀싱에서 나온 면역 세포의 다양한 유형을 모아놓은 데이터 입니다. 따라서 여러 유형의 면역 세포가 포함되어서 말초혈액 단핵세포 데이터를 분석하는 데 가장 적합합니다. 

[코드 9-7] singleR을 이용한 세포유형 맵핑
```{r, fig.width=15}
# if (!require(“BiocManager”, quietly = TRUE))
# 	install.packages(“BiocManager”)
# BiocManager::install(“celldex”)
# BiocManager::install("SingleR")
library(SingleR)
library(celldex)

# 비슷한 참조 데이터 불러오기 
ref.data <- MonacoImmuneData(ensembl=F)

# singleR 과 호환 가능한 singleCellExperiment 유형으로 변환하기 
sobj_SCE <- as.SingleCellExperiment(pbmc_alzheimer_SCT.combined, assay="SCT")
results <- SingleR(test = sobj_SCE, ref = ref.data, labels = ref.data$label.main) 

# 추측된 세포 유형 주석 데이터 추가하기 
pbmc_alzheimer_SCT.combined$MonacoImmuneData_main <- results$labels

# UMAP 시각화 
## 메인 주석
Idents(pbmc_alzheimer_SCT.combined) <- pbmc_alzheimer_SCT.combined$MonacoImmuneData_main 
DimPlot(pbmc_alzheimer_SCT.combined, label = T, reduction = "umap") 

# 각 클러스터별 주석 점수 힛맵
tab <- table(cluster = pbmc_alzheimer_SCT.combined$integrated_snn_res.0.3, label = results$labels)
pheatmap::pheatmap(log10(tab+10), cluster_cols = FALSE)
```


### scType
[코드 9-8] scType에 필요한 툴 및 함수들 다운받기 
```{r}
# 필요한 라이브러리 불러오기  
# BiocManager::install("HGNChelper")
library(HGNChelper)
library(openxlsx) # 엑셀 파일을 다루기 

# load gene set preparation function
source("https://raw.githubusercontent.com/IanevskiAleksandr/sc-type/master/R/gene_sets_prepare.R")
# load cell type annotation function
source("https://raw.githubusercontent.com/IanevskiAleksandr/sc-type/master/R/sctype_score_.R")

# 사용 할 유전자 마커 데이터 베이스 불러오기 ()
db_ = "https://raw.githubusercontent.com/IanevskiAleksandr/sc-type/master/ScTypeDB_full.xlsx";
tissue = "Immune system"
gs_list = gene_sets_prepare(db_, tissue)
```

[코드 9-9] scType에를 이용한 세포유형 맵핑
```{r}
# 유전자 발현 데이터를 불러와 세포 유형을 지정
es.max = sctype_score(scRNAseqData =  pbmc_alzheimer_SCT.combined[["integrated"]]@scale.data, scaled = TRUE,
                      gs = gs_list$gs_positive, gs2 = gs_list$gs_negative) 

# 클러스터 별로 합치기
cL_resutls = do.call("rbind", lapply(unique(pbmc_alzheimer_SCT.combined@meta.data$integrated_snn_res.0.3), function(cl){
    es.max.cl = sort(rowSums(es.max[ ,rownames(pbmc_alzheimer_SCT.combined@meta.data[pbmc_alzheimer_SCT.combined@meta.data$integrated_snn_res.0.3==cl, ])]), decreasing = !0)
    head(data.frame(cluster = cl, type = names(es.max.cl), scores = es.max.cl, ncells = sum(pbmc_alzheimer_SCT.combined@meta.data$integrated_snn_res.0.3==cl)), 10)
}))

# 각 클러스터별로 가장 점수가 높은 세포유형으로 주석하기 
sctype_scores = cL_resutls %>% group_by(cluster) %>% top_n(n = 1, wt = scores)  

# 확실하지 않은 (ScType 점수가 낮은) 클러스터는 "unknown"으로 지정하기 
sctype_scores$type[as.numeric(as.character(sctype_scores$scores)) < sctype_scores$ncells/4] = "Unknown"
```

[코드 9-10] scType를 이용한 세포유형 맵핑 시각화 
```{r}
pbmc_alzheimer_SCT.combined@meta.data$customclassif = ""
for(j in unique(sctype_scores$cluster)){
  cl_type = sctype_scores[sctype_scores$cluster==j,]; 
  pbmc_alzheimer_SCT.combined@meta.data$customclassif[pbmc_alzheimer_SCT.combined@meta.data$integrated_snn_res.0.3 == j] = as.character(cl_type$type[1])
}

# pdf("../singleCell_practice/results/UMAP_scType.pdf", width = 10)
DimPlot(pbmc_alzheimer_SCT.combined, reduction = "umap", label = TRUE, repel = TRUE, group.by = 'customclassif') 
# dev.off()

# saveRDS(pbmc_alzheimer_SCT.combined, "./rds/pbmc_alzheimer_SCT.combined_scTYPE.rds")
```

```{r}
# 함수 불러오기
source("https://raw.githubusercontent.com/IanevskiAleksandr/sc-type/master/R/auto_detect_tissue_type.R")
db_ = "https://raw.githubusercontent.com/IanevskiAleksandr/sc-type/master/ScTypeDB_full.xlsx";

# 조직 유형 유추하기
tissue_guess = auto_detect_tissue_type(path_to_db_file = db_, seuratObject = pbmc_alzheimer_SCT.combined, scaled = TRUE, assay = "SCT") 
# assay = "integrated"
# Error in h(simpleError(msg, call)) : 
#   error in evaluating the argument 'x' in selecting a method for function 'rowSums': incorrect number of
```

### scanVI
[코드 9-] scanVI 를 위한 라이브러리 설치 및 Seurat 오브젝트 변환 
```{r}
install.packages("reticulate") # python함수를 R에서 사용가능하게 도와주는 라이브러리 (TODO : 체크 하기) 
install.packages("cowplot")    # ggplot를 활용한 시각화를 도와주는 툴 
# install.packages("devtools")   # CRAN뿐 아니라 github, bioconductor 등에서도 쉽게 라이브러리를 설치 할 수 있도록 도와주는 툴 
library(devtools)
devtools::install_github("cellgeni/sceasy")
library(reticulate)
library(cowplot)
library(sceasy)

# Seurat 오브젝트를 AnnData 오브젝트로 변형하기 
sc <- import("scanpy", convert = FALSE)
scvi <- import("scvi", convert = FALSE)
adata <- convertFormat(pbmc_alzheimer_SCT.combined, from="seurat", to="anndata", main_layer="counts", drop_single_values=FALSE)
print(adata) # Note generally in Python, dataset conventions are obs x var
```

# 챕터 10 단일 세포 데이터 후속 분석 
... 일단 dev 에서 진행 
```{r}
# 위에서 진행한 코드 
# DefaultAssay(pbmc_alzheimer_SCT.combined) <- "integrated"

Idents(pbmc_alzheimer_SCT.combined) <- "subject_status"
degs_severeADvsnormal <- FindMarkers(pbmc_alzheimer_SCT.combined, ident.1 = "patient with severe AD", ident.2 = "normal individual", only.pos = FALSE)
saveRDS(degs_severeADvsnormal, "./rds/degs_severeADvsnormal.rds")
```

# 챕터 11 추가 분석 툴들 
## 11.1 품질 관리(QC)
### 11.1.1 두방울 세포 제거
#### DoubletFinder
```{r}
# DoubleFinder 설치 및 불러오기 
install.packages("remotes")
remotes::install_github('chris-mcginnis-ucsf/DoubletFinder')
library(DoubletFinder)

# 각 샘플마다 최근접 이웃 (NN) 찾기 및 SNN 그래프 구축 
pbmc_alzheimer_SCT.list_processed <- lapply(pbmc_alzheimer_SCT.list, function(sobj) {  
    sobj <- sobj %>%  
      SCTransform(.,verbose = FALSE) %>%
      RunPCA(., verbose = FALSE) %>%
      RunUMAP(., reduction = "pca", dims = 1:30, verbose = FALSE) %>%
      FindNeighbors(., reduction = "pca", dims = 1:30) %>% 
      FindClusters(., resolution = c(0.3)) # option
}) 

# 각 샘플마다 두 세포 방울 찾기  
pbmc_alzheimer_SCT.list_processed_doublefinder <- lapply(pbmc_alzheimer_SCT.list_processed, function(sobj) {  
  # 예시로 전체 세포의 7.5%를 예상 두방울 수로 설정
  nExp_poi <- round(0.075 * nrow(sobj@meta.data))
  # DoubletFinder 실행 
  sobj_doublefinder <- doubletFinder(sobj, PCs = 1:10, pN = 0.25, pK = 0.09, nExp = nExp_poi, reuse.pANN = FALSE, sct = TRUE) 
})
```

[코드 11-3] DoubletFinder 실행 결과 시각화 예시 
```{r}
# DoubletFinder 결과 확인 
pbmc_alzheimer_SCT.list_processed_doublefinder[[1]]@meta.data[1:5,]

# UMAP 시각화 
DimPlot(pbmc_alzheimer_SCT.list_processed_doublefinder[[1]],  group.by = "DF.classifications_0.25_0.09_860") 
```

#### scDblFinder
```{r}

```




