---
title: "singleCell_분석_기초"
author: "yeji Bae"
date: "2023-10-10"
output: html_document
---

해당 스크립트는 "실전 단일세포 데이터 분석: 예제 코드와 데이터로 배우는 생물정보 분석 기술" 책에서 따라 할 수 있도록 제작된 실습 스크립트 '기초편' 입니다. 

현재 보고 계시는 코드는 제일 기본 코드이며, 조금 더 심화된 코드를 확인 하고 싶다면 singleCell_분석_고급편.Rmd 파일을 확인해주세요.

만약, 단일 세포 분석이 처음이시라면, 기초, 중급, 고급 스크립트를 하나씩 소화해 나가시길 추천합니다. 

각 코드블럭에 대한 자세한 설명은 언급되어 있는 챕터에 나와있는 설명들을 참고바랍니다. 

질문 사항이 있거나, 코드를 돌리는데 어려움이 있다면 github페이지에서 -> 'issue' 탭 -> 'New issue' 버튼을 클릭해서 작성해주시면 빠른 시일내에 답변드리겠습니다. 

**도협 박사님! 'Question' 이라고 적은 부분과 주석들을 자세히 읽고 피드백 부탁 드립니다.**
Question: R script or Rmd script? 

```{r setup, include=FALSE} 
# knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
knitr::opts_chunk$set(echo = TRUE)
# setwd("/Users/ybae/Desktop/YJ/singleCell_book/src/singleCell_practice/")
```

# 필요한 라이브러리 불러오기 
챕터 02-02 'R 패키지 설치 및 실행' 참고 
```{r}
# install.packages("SeuratObject")
# install.packages("Seurat") -> 5.0.1 on 2024.01.16
library(Seurat)
library(dplyr)
```

# 챕터 05  "Seurat Object 만들기, 품질관리 및 필터링"
## 챕터 05-01 "Seurat Object 만들기"

[코드 5 - 1] 2가지 방법으로 Seurat 오브젝트 만들기 (Question - 책에서는 타이틀을 코드 블럭 아래에 두었는데 여기는 위? 아래? )
```{r}
# [1] h5 파일 이용하기
count_SRR13911909.h5 <- Read10X_h5("./singleCell/results/count_SRR13911909/outs/filtered_feature_bc_matrix.h5", use.names = TRUE, unique.features = TRUE)
SRR13911909.h5.sobj <- CreateSeuratObject(counts = count_SRR13911909.h5, project = "pbmc_alzheimer")

# [2] filtered_feature_bc_matrix folder 폴더 이용하기 
SRR13911909 <- Read10X(data.dir =  "./singleCell/results/count_SRR13911909/outs/filtered_feature_bc_matrix/" )
SRR13911909.sobj <- CreateSeuratObject(counts = SRR13911909, project = "pbmc_alzheimer")
```

[코드 5-1.1] 코드 시간 재기 
```{r}
# 코드가 얼마나 걸리는지 시간 재기 (예시). 이 때, 해당 코드 블럭을 한번에 실행시켜줘야 정확한 시간을 얻을 수 있습니다. 하이라이트 한 뒤 실행 시키면 한번에 실행 가능합니다. 
# [1] h5 파일 이용하기
start <- Sys.time() # 시작 시간 
count_SRR13911909.h5 <- Read10X_h5("./singleCell/results/count_SRR13911909/outs/filtered_feature_bc_matrix.h5", use.names = TRUE, unique.features = TRUE)
SRR13911909.h5.sobj <- CreateSeuratObject(counts = count_SRR13911909.h5, project = "pbmc_alzheimer")
print( Sys.time() - start ) # 현재 시간 – 시작 시간  = 총 걸린 시간

# [2] filtered_feature_bc_matrix folder 폴더 이용하기 
start <- Sys.time()
SRR13911909 <- Read10X(data.dir = "./singleCell/results/count_SRR13911909/outs/filtered_feature_bc_matrix/")
SRR13911909.sobj <- CreateSeuratObject(counts = pbmc_alzheimer.SRR13911909, project = "pbmc_alzheimer")
print( Sys.time() - start )
```


[코드 5 - 2] 모든 샘플을 Seurat 오브젝트로 변형하기
!! library(hdf5r) 설치 필요할수도 있을 것 같습니다. scratch 부터 시작했을때 설치 요구했습니다. 
```{r}
# 각 샘플마다 raw matrix 를 Seurat object 로 생성하기
count_SRR13911909.h5 <- Read10X_h5("./filtered_feature_bc_matrix_SRR13911909.h5", use.names = TRUE, unique.features = TRUE)
SRR13911909.h5.sobj <- CreateSeuratObject(counts = count_SRR13911909.h5, project = "pbmc_alzheimer", min.cells = 3, min.features = 200)

count_SRR13911910.h5 <- Read10X_h5("./filtered_feature_bc_matrix_SRR13911910.h5", use.names = TRUE, unique.features = TRUE)
SRR13911910.h5.sobj <- CreateSeuratObject(counts = count_SRR13911910.h5, project = "pbmc_alzheimer", min.cells = 3, min.features = 200)

count_SRR13911911.h5 <- Read10X_h5("./filtered_feature_bc_matrix_SRR13911911.h5", use.names = TRUE, unique.features = TRUE)
SRR13911911.h5.sobj <- CreateSeuratObject(counts = count_SRR13911911.h5, project = "pbmc_alzheimer", min.cells = 3, min.features = 200)

count_SRR13911912.h5 <- Read10X_h5("./filtered_feature_bc_matrix_SRR13911912.h5", use.names = TRUE, unique.features = TRUE)
SRR13911912.h5.sobj <- CreateSeuratObject(counts = count_SRR13911912.h5, project = "pbmc_alzheimer", min.cells = 3, min.features = 200)

count_SRR13911913.h5 <- Read10X_h5("./filtered_feature_bc_matrix_SRR13911913.h5", use.names = TRUE, unique.features = TRUE)
SRR13911913.h5.sobj <- CreateSeuratObject(counts = count_SRR13911913.h5, project = "pbmc_alzheimer", min.cells = 3, min.features = 200)

count_SRR13911914.h5 <- Read10X_h5("./filtered_feature_bc_matrix_SRR13911914.h5", use.names = TRUE, unique.features = TRUE)
SRR13911914.h5.sobj <- CreateSeuratObject(counts = count_SRR13911914.h5, project = "pbmc_alzheimer", min.cells = 3, min.features = 200)
```

Seurat 오브젝트 둘러보기 
```{r}
# seurat object 크기 확인하기
SRR13911909.h5.sobj
dim(SRR13911909.h5.sobj) # feature (gene) x cell 
colnames(SRR13911909.h5.sobj)[1:10] # cell barcode
rownames(SRR13911909.h5.sobj)[1:10] # feature (gene) name 

## 메타데이터 
SRR13911909.h5.sobj[[]] 
SRR13911909.h5.sobj@meta.data 

## Assay
SRR13911909.h5.sobj@assays$RNA
SRR13911909.h5.sobj@assays$RNA$counts

## others 
SRR13911909.h5.sobj@ # @뒤에서 'tab'을 눌러서 어떤 데이터를 불러 올 수 있는지 확인해 보세요. 
```

## 챕터 05-02 '품질관리 (QC) 및 필터링'

[코드 5-3] 미토콘드리아 비율 구하기
```{r}
# 각 샘플마다 미토콘드리아 비율 구하기 
SRR13911909.h5.sobj[["percent.mt"]] <- PercentageFeatureSet(SRR13911909.h5.sobj, pattern = "^MT-")
SRR13911910.h5.sobj[["percent.mt"]] <- PercentageFeatureSet(SRR13911910.h5.sobj, pattern = "^MT-")
SRR13911911.h5.sobj[["percent.mt"]] <- PercentageFeatureSet(SRR13911911.h5.sobj, pattern = "^MT-")
SRR13911912.h5.sobj[["percent.mt"]] <- PercentageFeatureSet(SRR13911912.h5.sobj, pattern = "^MT-")
SRR13911913.h5.sobj[["percent.mt"]] <- PercentageFeatureSet(SRR13911913.h5.sobj, pattern = "^MT-")
SRR13911914.h5.sobj[["percent.mt"]] <- PercentageFeatureSet(SRR13911914.h5.sobj, pattern = "^MT-")
```

[코드 5-4,5] QC plots 시각화 하기 
```{r}
# Violoin plot 
VlnPlot(SRR13911909.h5.sobj, features = c("nFeature_RNA", "nCount_RNA", "percent.mt"), ncol = 3)
VlnPlot(SRR13911910.h5.sobj, features = c("nFeature_RNA", "nCount_RNA", "percent.mt"), ncol = 3)
VlnPlot(SRR13911911.h5.sobj, features = c("nFeature_RNA", "nCount_RNA", "percent.mt"), ncol = 3)
VlnPlot(SRR13911912.h5.sobj, features = c("nFeature_RNA", "nCount_RNA", "percent.mt"), ncol = 3)
VlnPlot(SRR13911913.h5.sobj, features = c("nFeature_RNA", "nCount_RNA", "percent.mt"), ncol = 3)
VlnPlot(SRR13911914.h5.sobj, features = c("nFeature_RNA", "nCount_RNA", "percent.mt"), ncol = 3)

# Scatter featrue plot [1] ncount x nfeature [2] ncount vs percent.mt  
FeatureScatter(SRR13911909.h5.sobj, feature1 = "nCount_RNA", feature2 = "nFeature_RNA") # [1]
FeatureScatter(SRR13911909.h5.sobj, feature1 = "nCount_RNA", feature2 = "percent.mt")   # [2]
FeatureScatter(SRR13911910.h5.sobj, feature1 = "nCount_RNA", feature2 = "nFeature_RNA")
FeatureScatter(SRR13911910.h5.sobj, feature1 = "nCount_RNA", feature2 = "percent.mt")
FeatureScatter(SRR13911911.h5.sobj, feature1 = "nCount_RNA", feature2 = "nFeature_RNA")
FeatureScatter(SRR13911911.h5.sobj, feature1 = "nCount_RNA", feature2 = "percent.mt")
FeatureScatter(SRR13911912.h5.sobj, feature1 = "nCount_RNA", feature2 = "nFeature_RNA")
FeatureScatter(SRR13911912.h5.sobj, feature1 = "nCount_RNA", feature2 = "percent.mt")
FeatureScatter(SRR13911913.h5.sobj, feature1 = "nCount_RNA", feature2 = "nFeature_RNA")
FeatureScatter(SRR13911913.h5.sobj, feature1 = "nCount_RNA", feature2 = "percent.mt")
FeatureScatter(SRR13911914.h5.sobj, feature1 = "nCount_RNA", feature2 = "nFeature_RNA")
FeatureScatter(SRR13911914.h5.sobj, feature1 = "nCount_RNA", feature2 = "percent.mt")
```

[코드 5-6] 위의 플롯들을 이용해서 필터링 하기 
```{r}
# 필터링 
SRR13911909.h5.sobj <- subset(SRR13911909.h5.sobj, subset = nFeature_RNA > 200 & nFeature_RNA < 3000 & percent.mt < 10)  
SRR13911910.h5.sobj <- subset(SRR13911910.h5.sobj, subset = nFeature_RNA > 200 & nFeature_RNA < 3000 & percent.mt < 10)
SRR13911911.h5.sobj <- subset(SRR13911911.h5.sobj, subset = nFeature_RNA > 200 & nFeature_RNA < 3000 & percent.mt < 10)
SRR13911912.h5.sobj <- subset(SRR13911912.h5.sobj, subset = nFeature_RNA > 200 & nFeature_RNA < 3000 & percent.mt < 10)
SRR13911913.h5.sobj <- subset(SRR13911913.h5.sobj, subset = nFeature_RNA > 200 & nFeature_RNA < 3000 & percent.mt < 10)
SRR13911914.h5.sobj <- subset(SRR13911914.h5.sobj, subset = nFeature_RNA > 200 & nFeature_RNA < 3000 & percent.mt < 10)
```

[코드 5-7] 필터링 된 데이터의 QC 플롯 그려보기 
```{r, fig.width = 10}
# 예시 - SRR13911909.h5.sobj
VlnPlot(SRR13911909.h5.sobj, features = c("nFeature_RNA", "nCount_RNA", "percent.mt"), ncol = 3)
FeatureScatter(SRR13911909.h5.sobj, feature1 = "nCount_RNA", feature2 = "percent.mt")
FeatureScatter(SRR13911909.h5.sobj, feature1 = "nCount_RNA", feature2 = "nFeature_RNA")

# Task: 다른 샘플들의 QC 플롯들도 그려보세요. (아래 테스트 삭제 해야함)
# count_SRR13911909.h5 <- Read10X_h5("./filtered_feature_bc_matrix_SRR13911909.h5", use.names = TRUE, unique.features = TRUE)
# SRR13911909.h5.sobj <- CreateSeuratObject(counts = count_SRR13911909.h5, project = "pbmc_alzheimer", min.cells = 3, min.features = 200)
# SRR13911909.h5.sobj[["percent.mt"]] <- PercentageFeatureSet(SRR13911909.h5.sobj, pattern = "^MT-")
# SRR13911909.h5.sobj <- subset(SRR13911909.h5.sobj, subset = nFeature_RNA > 200 & nFeature_RNA < 3000 & percent.mt < 10)  
# VlnPlot(SRR13911909.h5.sobj, features = c("nFeature_RNA", "nCount_RNA", "percent.mt"), ncol = 3)
# FeatureScatter(SRR13911909.h5.sobj, feature1 = "nCount_RNA", feature2 = "percent.mt")
# FeatureScatter(SRR13911909.h5.sobj, feature1 = "nCount_RNA", feature2 = "nFeature_RNA")
```



# 챕터 06 "데이터 정규화 및 통합"
= Normalization + Integration + Dimension reduction

Question - 해당 부분 보완 가능하면 부탁드립니다 

방법 1: 각 샘플을 정규화 한 후, 합치기 
방법 2 : 모든 샘플을 합친 후, 한번에 정규화 하기 

## Log normalization
챕터 06-01-로그정규화 이용 

- *NormalizeData()*: https://satijalab.org/seurat/reference/normalizedata 
- *merge()*: https://satijalab.org/seurat/articles/seurat5_merge_vignette#merging-more-than-two-seurat-objects
[코드 6-1] 로그 정규화 방법 1
```{r}
# 방법 1 # 
# 샘플 별 정규화 진행하기 
SRR13911909.h5.sobj_norm <- NormalizeData(SRR13911909.h5.sobj) 
SRR13911910.h5.sobj_norm <- NormalizeData(SRR13911910.h5.sobj)
SRR13911911.h5.sobj_norm <- NormalizeData(SRR13911911.h5.sobj)
SRR13911912.h5.sobj_norm <- NormalizeData(SRR13911912.h5.sobj)
SRR13911913.h5.sobj_norm <- NormalizeData(SRR13911913.h5.sobj)
SRR13911914.h5.sobj_norm <- NormalizeData(SRR13911914.h5.sobj)

# 정규환 된 슈랏 오브젝트들 합쳐주기 
pbmc_alzheimer_lognorm_1 <- merge(SRR13911909.h5.sobj_norm, 
                              y = c(SRR13911910.h5.sobj_norm,SRR13911911.h5.sobj_norm,SRR13911912.h5.sobj_norm,SRR13911913.h5.sobj_norm,SRR13911914.h5.sobj_norm),
                              add.cell.ids = c("SRR13911909", "SRR13911910", "SRR13911911", "SRR13911912", "SRR13911913", "SRR13911914"), 
                              project = "pbmc_alzheimer", 
                              merge.data = TRUE)

# 유의미한 유전자 추출하기 (feature selection)
pbmc_alzheimer_lognorm_1 <- FindVariableFeatures(pbmc_alzheimer_lognorm_1, selection.method = "vst", nfeatures = 2000)



# 스케일링  
pbmc_alzheimer_lognorm_1 <- ScaleData(pbmc_alzheimer_lognorm_1) # features = all.genes

# by default scaling only variable features, but we can use all genes
# all.genes <- rownames(pbmc_alzheimer_Log_1)
# pbmc_alzheimer_Log_1 <- ScaleData(pbmc_alzheimer_Log_1, features = all.genes)
```


[코드 6-4] 여러 카운트 값 비교하기 
```{r}
# raw 데이터 
pbmc_alzheimer_Log_1[["RNA"]]$counts.1 # 혹은 pbmc_alzheimer_Log_1@assays$RNA$counts.1

# 정규화 된 데이터 
pbmc_alzheimer_Log_1[["RNA"]]$data.1

# 스케일링 된 데이터 
pbmc_alzheimer_Log_1[["RNA"]]$scale.data[1:5, 1:2]
```



[코드 6-5] 로그 정규화 방법 2
```{r}
# 방법 2 # 
# 각 슈랏 오브젝트들 합지기 
pbmc_alzheimer_lognorm_2 <- merge(SRR13911909.h5.sobj, y = c(SRR13911910.h5.sobj, SRR13911911.h5.sobj,SRR13911912.h5.sobj,SRR13911913.h5.sobj,SRR13911914.h5.sobj), add.cell.ids = c("SRR13911909", "SRR13911910", "SRR13911911", "SRR13911912", "SRR13911913", "SRR13911914"), project = "pbmc_alzheimer")

# 한번에 로그정규화 진행하기 
pbmc_alzheimer_lognorm_2 <- NormalizeData(pbmc_alzheimer_lognorm_2, scale.factor = 10000)
## Q. 이때도, 각 count 를 따로 Normalize 해주는데 위에 방법이랑 뭐가 다를까? 

# 유의미한 유전자 추출하기 (feature selection)
pbmc_alzheimer_lognorm_2 <- FindVariableFeatures(pbmc_alzheimer_lognorm_2, selection.method = "vst", nfeatures = 2000)

# 스케일링
pbmc_alzheimer_lognorm_2 <- ScaleData(pbmc_alzheimer_lognorm_2)
```
```{r}
identical(pbmc_alzheimer_lognorm_2@assays$RNA@layers$data.2, pbmc_alzheimer_lognorm_1@assays$RNA@layers$data.2) # TRUE
identical(pbmc_alzheimer_lognorm_2@assays$RNA@layers$scale.data, pbmc_alzheimer_lognorm_1@assays$RNA@layers$scale.data) # TRUE
```

JoinLayers?? which collapses the individual datasets together and recreates the original counts and data layers.
https://satijalab.org/seurat/articles/seurat5_integration.html
```{r}
pbmc_alzheimer_lognorm_1_joined <- JoinLayers(pbmc_alzheimer_lognorm_1)
```

[코드 6-6] 다시.... 새로운 코드 (2024.04.20)
```{r}
lognorm_list <- lapply(c(SRR13911909.h5.sobj, SRR13911910.h5.sobj, SRR13911911.h5.sobj,
                      SRR13911912.h5.sobj,SRR13911913.h5.sobj,SRR13911914.h5.sobj), function(x) {
  x <- NormalizeData(x)
  x <- FindVariableFeatures(x, selection.method = "vst", nfeatures = 2000)
})
features <- SelectIntegrationFeatures(object.list = lognorm_list, nfeatures=10000)
lognorm_anchors <- FindIntegrationAnchors(object.list = lognorm_list, anchor.features = features)
lognorm_combined <- IntegrateData(anchorset = lognorm_anchors)
DefaultAssay(lognorm_combined) <- "integrated"
lognorm_combined <- ScaleData(lognorm_combined, verbose = FALSE)
lognorm_combined <- RunPCA(lognorm_combined, npcs = 30, verbose = FALSE)
lognorm_combined <- RunUMAP(CB30_combined, reduction = "pca", dims = 1:30)
lognorm_combined <- FindNeighbors(lognorm_combined, dims = 1:30)
lognorm_combined <- FindClusters(lognorm_combined, resolution = 0.8)
```

Question - Log normalization 한 후 Integration? 

```{r}
# 2024 to demo merged without integration -> to see batch effect 
pbmc_alzheimer_Log_2 <- merge(SRR13911909.h5.sobj, y = c(SRR13911910.h5.sobj, SRR13911911.h5.sobj,SRR13911912.h5.sobj,SRR13911913.h5.sobj,SRR13911914.h5.sobj), add.cell.ids = c("SRR13911909", "SRR13911910", "SRR13911911", "SRR13911912", "SRR13911913", "SRR13911914"), project = "pbmc_alzheimer")


dim(pbmc_alzheimer_Log_2[["RNA"]]$counts.1) #  21423 11325
dim(pbmc_alzheimer_Log_2_joined[["RNA"]]$counts) # 24164 74134 
pbmc_alzheimer_Log_2
 
pbmc_alzheimer_Log_2_joined <- pbmc_alzheimer_Log_2
pbmc_alzheimer_Log_2_joined[["RNA"]] <- JoinLayers(pbmc_alzheimer_Log_2_joined[["RNA"]]) # all the counts into one count 

pbmc_alzheimer_Log_2_joined <- SCTransform(pbmc_alzheimer_Log_2_joined, verbose = FALSE)  # need? -> sure for the same condition

pbmc_alzheimer_Log_2_joined@meta.data <- pbmc_alzheimer_Log_2_joined@meta.data %>%
  mutate(Run = ifelse(grepl("SRR13911909_", rownames(.)), "SRR13911909", 
                              ifelse(grepl("SRR13911910_", rownames(.)), "SRR13911910",
                                     ifelse(grepl("SRR13911911_", rownames(.)), "SRR13911911",
                                            ifelse(grepl("SRR13911912_", rownames(.)), "SRR13911912",
                                                   ifelse(grepl("SRR13911913_", rownames(.)), "SRR13911913",
                                                          ifelse(grepl("SRR13911914_", rownames(.)), "SRR13911914", "NA")))))))

# manifest
manifest <- read.csv("SraRunTable.txt")
manifest <- manifest %>% # 필요한 컬럼만 추출해내기 
  select(c(Run, Age, subject_status))

pbmc_alzheimer_Log_2_joined@meta.data[c("Run", "Age", "subject_status")] <-
  manifest[match(pbmc_alzheimer_Log_2_joined$Run, manifest$Run), ]
# saveRDS(pbmc_alzheimer_Log_2_joined, "./rds/pbmc_alzheimer_Log_2_joined.rds")



# UMAP group by age 
DimPlot(
  pbmc_alzheimer_Log_2_joined,
  reduction = "umap.rna.cca",
  group.by = c("Age"),
  combine = FALSE, label.size = 2
)
```

## SCTransform
챕터 06-01-SCTranfrom정규화 이용 
"https://satijalab.org/seurat/articles/sctransform_vignette" 에서 더 자세한 내용을 확인 할 수 있습니다. 

우리는 방법 1을 이용해서 추후 후속 분석을 진행할 예정입니다.

*SCTransform()*: https://satijalab.org/seurat/reference/sctransform 

[코드 6-4] SCTransform 방법 1 
[코드 6-5] SCTransform 을 이용하여 데이터 합치기 (Integration)
```{r}
# 방법 1 # 
# 샘플 별 정규화 진행하기 
SRR13911909.h5.sobj_SCT <- SCTransform(SRR13911909.h5.sobj, vars.to.regress = "percent.mt", verbose = FALSE) %>%
  RunPCA(npcs = 30, verbose = FALSE)
SRR13911910.h5.sobj_SCT <- SCTransform(SRR13911910.h5.sobj, vars.to.regress = "percent.mt", verbose = FALSE) %>%
    RunPCA(npcs = 30, verbose = FALSE)
SRR13911911.h5.sobj_SCT <- SCTransform(SRR13911911.h5.sobj, vars.to.regress = "percent.mt", verbose = FALSE) %>%
    RunPCA(npcs = 30, verbose = FALSE)
SRR13911912.h5.sobj_SCT <- SCTransform(SRR13911912.h5.sobj, vars.to.regress = "percent.mt", verbose = FALSE) %>%
    RunPCA(npcs = 30, verbose = FALSE)
SRR13911913.h5.sobj_SCT <- SCTransform(SRR13911913.h5.sobj, vars.to.regress = "percent.mt", verbose = FALSE) %>%
    RunPCA(npcs = 30, verbose = FALSE)
SRR13911914.h5.sobj_SCT <- SCTransform(SRR13911914.h5.sobj, vars.to.regress = "percent.mt", verbose = FALSE) %>%
    RunPCA(npcs = 30, verbose = FALSE)


# 여러 seurat object 를 하나의 리스트로 묶기 
## TODO:굳이 이름 주어야하나
pbmc_alzheimer_SCT.list <- list(SRR13911909.h5.sobj_SCT = SRR13911909.h5.sobj_SCT, SRR13911910.h5.sobj_SCT = SRR13911910.h5.sobj_SCT,
                  SRR13911911.h5.sobj_SCT = SRR13911911.h5.sobj_SCT, SRR13911912.h5.sobj_SCT = SRR13911912.h5.sobj_SCT,
                  SRR13911913.h5.sobj_SCT = SRR13911913.h5.sobj_SCT , SRR13911914.h5.sobj_SCT = SRR13911914.h5.sobj_SCT)
# saveRDS(pbmc_alzheimer_SCT.list, "./rds/pbmc_alzheimer_SCT.list.rds")
# pbmc_alzheimer_SCT.list <- readRDS("./rds/pbmc_alzheimer_SCT.list.rds")
## 데이터가 큰 단일 세포를 분석할 때는, 오래 걸리는 함수를 돌린 후 나온 결과를 rds 파일 형태로 저장합니다.
## 이는 다음에 이어서 분석을 진행할때 처음부터 다시 돌릴 필요 없이, 저장해 둔 rds 파일을 불러와 진행시키기 위함입니다. 

# 정규화 된 seurat object 합치기 
features <- SelectIntegrationFeatures(object.list = pbmc_alzheimer_SCT.list, nfeatures = 3000) 
pbmc_alzheimer_SCT.list <- PrepSCTIntegration(object.list = pbmc_alzheimer_SCT.list, anchor.features = features) ## TODO 이게 뭐하는건지 확인 

# 샘플 간의 앵커 찾기
pbmc_alzheimer_SCT.anchors <- FindIntegrationAnchors(object.list = pbmc_alzheimer_SCT.list, 
                                                     normalization.method = "SCT", 
                                                     anchor.features = features,
                                                     reduction = "cca") # TODO: PCA 안돌렸는데도 돌아가네..????? Anchor를어떻게 찾는거지? 
pbmc_alzheimer_SCT.combined <- IntegrateData(anchorset = pbmc_alzheimer_SCT.anchors, 
                                             normalization.method = "SCT") # 메모리가 부족하면 (64GB 미만) 터질 수 있습니다.
# saveRDS(pbmc_alzheimer_SCT.anchors, "./rds/pbmc_alzheimer_SCT.anchors.rds")
# saveRDS(pbmc_alzheimer_SCT.combined, "./rds/sobj_SCT_merged_method.rds")
```

```{r}
# 2024.03.02 데이터 확인 
# ---- Raw RNA  ---------
SRR13911909.h5.sobj # total 21423 feature 
dim(SRR13911909.h5.sobj[["RNA"]]$counts) # 21423 11325

# ---- SCTransformed ---------
SRR13911909.h5.sobj_SCT # Q. why the total features 21423(RNA) + 19521(SCT) = 40944? aren't most of them redundant? 
table(rownames(SRR13911909.h5.sobj_SCT[["RNA"]]) %in% rownames(SRR13911909.h5.sobj_SCT[["SCT"]]))
# FALSE  TRUE 
#  1902 19521 

disapeared_features <- rownames(SRR13911909.h5.sobj_SCT[["RNA"]])[!rownames(SRR13911909.h5.sobj_SCT[["RNA"]]) %in% rownames(SRR13911909.h5.sobj_SCT[["SCT"]])]
length(rownames(SRR13911909.h5.sobj_SCT[["RNA"]])[!rownames(SRR13911909.h5.sobj_SCT[["RNA"]]) %in% rownames(SRR13911909.h5.sobj_SCT[["SCT"]])]) # 1902 not in SCT features 
SRR13911909.h5.sobj_SCT[["RNA"]]$counts[disapeared_features,][1:20, 1:20] %>% as.matrix() 
# Q. what is the standard to filter out ?
table(rowSums(SRR13911909.h5.sobj_SCT[["RNA"]]$counts[disapeared_features,]))
table(rowSums(SRR13911909.h5.sobj_SCT[["RNA"]]$counts[,]))


identical(SRR13911909.h5.sobj_SCT[["RNA"]]$counts, SRR13911909.h5.sobj_SCT[["SCT"]]$counts) # FALSE
dim(SRR13911909.h5.sobj_SCT[["RNA"]]$counts) # 21423 11325
dim(SRR13911909.h5.sobj_SCT[["SCT"]]$counts) # 19521 11325
dim(SRR13911909.h5.sobj_SCT[["SCT"]]$data) # 19521 11325
dim(SRR13911909.h5.sobj_SCT[["SCT"]]$scale.data)  #  3000 11325
SRR13911909.h5.sobj_SCT[["RNA"]]$counts[1:10, 1:10]
SRR13911909.h5.sobj_SCT[["SCT"]]$counts[1:10, 1:10]
SRR13911909.h5.sobj_SCT[["SCT"]]$data[1:10, 1:10]
SRR13911909.h5.sobj_SCT[["SCT"]]$scale.data[1:10, 1:10]

# ---- FindIntegration feature --------
identical(rownames(SRR13911909.h5.sobj_SCT[["SCT"]]$scale.data), rownames(SRR13911914.h5.sobj_SCT[["SCT"]]$scale.data)) # FALSE 
identical(rownames(pbmc_alzheimer_SCT.list$SRR13911909.h5.sobj_SCT[["SCT"]]$scale.data), rownames(pbmc_alzheimer_SCT.list$SRR13911914.h5.sobj_SCT[["SCT"]]$scale.data)) # TRUE


#----- Integrate --------------------
# SCT 
dim(pbmc_alzheimer_SCT.combined[["SCT"]]) #  21737 74134
dim(pbmc_alzheimer_SCT.combined[["SCT"]]$counts) # 19521 x 74134 
identical(SRR13911909.h5.sobj_SCT[["SCT"]]$counts, pbmc_alzheimer_SCT.combined[["SCT"]]$counts) # FALSE
identical(rownames(SRR13911909.h5.sobj_SCT[["SCT"]]$counts), rownames(pbmc_alzheimer_SCT.combined[["SCT"]]$counts)) # TRUE Q. 왜 같은가?
identical(rownames(SRR13911914.h5.sobj_SCT[["SCT"]]$counts), rownames(pbmc_alzheimer_SCT.combined[["SCT"]]$counts)) # FALSE

SRR13911909.h5.sobj_SCT[["SCT"]]$counts[1:5,1:5]
pbmc_alzheimer_SCT.combined[["SCT"]]$counts[1:10,1:5]
pbmc_alzheimer_SCT.combined[["SCT"]]$data[1:10,1:5]
pbmc_alzheimer_SCT.combined[["SCT"]]$data[1:10,1:5]
dim(pbmc_alzheimer_SCT.combined[["integrated"]]$data)
pbmc_alzheimer_SCT.combined[["integrated"]]$scale.data[1:10, 1:5]

# integrated
# Q. why data vs scale.data different? -> maybe just normalized, and scaled ?
# Q. SCT assay 의 카운트 값들은 어디서 나온것? -> corrected 라고 하는데 어찌계산된 값들일까나 
# joinlayers() of RNA -> SCTransform 하면 SCT assay 값이 나오려나? 
DefaultAssay(pbmc_alzheimer_SCT.combined) <- "RNA"
pbmc_alzheimer_SCT.combined <- JoinLayers(pbmc_alzheimer_SCT.combined)
pbmc_alzheimer_SCT.combined <- SCTransform(pbmc_alzheimer_SCT.combined, vars.to.regress = "percent.mt", new.assay.name = "joined_SCT",verbose = FALSE) %>%
  RunPCA(npcs = 30, verbose = FALSE)

# saveRDS(pbmc_alzheimer_SCT.combined, "./rds/pbmc_alzheimer_SCT.combined_testing_march.rds")

# 실험하기 RNA assay 이용해서 JoinLayer() 와, integratelayers(), merge?() 차이점확인해보기 
```

```{r}
# pbmc_alzheimer_SCT.combined <- readRDS("./rds/pbmc_alzheimer_SCT.combined_2.rds")  # 2024.01.16 
# (메모용) pbmc_alzheimer_SCT.combined_1.rds, mt < 5%
# (메모용) pbmc_alzheimer_SCT.combined_2.rds, mt < 10%, min.cell = 3, min.features = 200, regress=mt
# (Question) Active assay: integrated (2000 features, 2000 variable features) why 2000 features?? i thought i used 3000 , check with him
```

[코드 6-6] SCTransform 방법 2
```{r}
# 방법 2 # 
pbmc_alzheimer_2 <- merge(SRR13911909.h5.sobj, y = c(SRR13911910.h5.sobj, SRR13911911.h5.sobj,SRR13911912.h5.sobj,SRR13911913.h5.sobj,SRR13911914.h5.sobj), add.cell.ids = c("SRR13911909", "SRR13911910", "SRR13911911", "SRR13911912", "SRR13911913", "SRR13911914"), project = "pbmc_alzheimer")
# saveRDS(pbmc_alzheimer_2, "./rds/pbmc_alzheimer_2.rds")

pbmc_alzheimer_2_SCT <- SCTransform(pbmc_alzheimer_2, verbose = FALSE) 
```


[코드 6-7] 메타 데이터 추가하기 
```{r}
# 'Run' = 샘플 이름 추가하기 
pbmc_alzheimer_SCT.combined@meta.data <- pbmc_alzheimer_SCT.combined@meta.data %>%
  mutate(Run = ifelse(grepl("_1", rownames(.)), "SRR13911909", 
                              ifelse(grepl("_2", rownames(.)), "SRR13911910",
                                     ifelse(grepl("_3", rownames(.)), "SRR13911911",
                                            ifelse(grepl("_4", rownames(.)), "SRR13911912",
                                                   ifelse(grepl("_5", rownames(.)), "SRR13911913",
                                                          ifelse(grepl("_6", rownames(.)), "SRR13911914", "NA")))))))

# manifest
manifest <- read.csv("SraRunTable.txt")
manifest <- manifest %>% # 필요한 컬럼만 추출해내기 
  select(c(Run, Age, subject_status))

pbmc_alzheimer_SCT.combined@meta.data[c("Run", "Age", "subject_status")] <-
  manifest[match(pbmc_alzheimer_SCT.combined$Run, manifest$Run), ]
```

# 07 "차원 축소 및 클러스터링" 

SCTransform [방법 1]을 이어서 진행합니다. 
  - _RunPCA()_: PCA on the scaled data
  - _RunUMAP()_
  - _FindNeighbors()_
  - _FindClusters()_ 


[코드 7-1] PCA 차원 축소 
합쳐진 데이터에 선형 및 비차원축소를 적용하여, 데이터들의 세포 구성을 확인해보겠습니다. 

(예전) 위에서 SCTransform 변형한 데이터들을 합쳐주기 위해서 미리 진행한 PCA 를 자세히 들여다보겠습니다. -> NOPE 이건 다시 진행해야한다. 
```{r, fig.width = 15}
DefaultAssay(pbmc_alzheimer_SCT.combined) <- "integrated"
pbmc_alzheimer_SCT.combined <- RunPCA(pbmc_alzheimer_SCT.combined, verbose = FALSE)

# Idents(pbmc_alzheimer_SCT.combined) <-  "orig.ident"
# pdf("./results/pca_results.pdf", width = 10)
print(pbmc_alzheimer_SCT.combined[["pca"]], dims = 1:10, nfeatures = 5)
DimPlot(pbmc_alzheimer_SCT.combined, reduction = "pca") + NoLegend() # 나중에 clustering 한 후에, 해당 색칠해서 확인해보면 어느 pc dimension이 어떤 cell type을 구분할 수 있는지도 보인다. 
ElbowPlot(pbmc_alzheimer_SCT.combined, ndims = 30, reduction = 'pca') # -> 20 dimension 사용 예정
DimHeatmap(pbmc_alzheimer_SCT.combined, dims = 1:9, cells = 500, balanced = TRUE)
# dev.off()
```

[코드 7-2] TSNE
```{r}
# TSNE
pbmc_alzheimer_SCT.combined <- RunTSNE(pbmc_alzheimer_SCT.combined, reduction = "pca", dims = 1:20, verbose = FALSE)
```

[코드 7-3] UMAP
```{r}
# UMAP
pbmc_alzheimer_SCT.combined <- RunUMAP(pbmc_alzheimer_SCT.combined, reduction = "pca", dims = 1:20, verbose = FALSE)
```

[코드 7-4] 클러스터링 
```{r}
pbmc_alzheimer_SCT.combined <- FindNeighbors(pbmc_alzheimer_SCT.combined, reduction = "pca", dims = 1:20)
pbmc_alzheimer_SCT.combined <- FindClusters(pbmc_alzheimer_SCT.combined, resolution = c(0.1,0.3, 0.5))
```

[참고] 차원축소 및 클러스터링 한번에 진행하기 
```{r}
pbmc_alzheimer_SCT.combined <- RunPCA(pbmc_alzheimer_SCT.combined, verbose = FALSE) %>%
  RunUMAP(., reduction = "pca", dims = 1:20, verbose = FALSE) %>%
  FindNeighbors(., reduction = "pca", dims = 1:20) %>% 
  FindClusters(., resolution = c(0.1, 0.3, 0.5))
```

[코드 7-4] UMAP/TSNE 시각화 
```{r, fig.width = 15}
# visualization
pdf("./results/UMAP_TSNE_integrated_snn_res.0.1_0.3_0.5.pdf", width = 10)
Idents(pbmc_alzheimer_SCT.combined) <- "integrated_snn_res.0.1"
DimPlot(pbmc_alzheimer_SCT.combined, label = T, label.size = 7, reduction = "umap")
DimPlot(pbmc_alzheimer_SCT.combined, label = T, label.size = 7, reduction = "tsne")

Idents(pbmc_alzheimer_SCT.combined) <- "integrated_snn_res.0.3"
DimPlot(pbmc_alzheimer_SCT.combined, label = T, label.size = 7, reduction = "umap")
DimPlot(pbmc_alzheimer_SCT.combined, label = T, label.size = 7, reduction = "tsne")

Idents(pbmc_alzheimer_SCT.combined) <- "integrated_snn_res.0.5"
DimPlot(pbmc_alzheimer_SCT.combined, label = T, label.size = 7, reduction = "umap")
DimPlot(pbmc_alzheimer_SCT.combined, label = T, label.size = 7, reduction = "tsne")
dev.off()
```

```{r}
# saveRDS(pbmc_alzheimer_SCT.combined, "./rds/pbmc_alzheimer_SCT.combined_2_clustered_2024.rds")
pbmc_alzheimer_SCT.combined <- readRDS("./rds/pbmc_alzheimer_SCT.combinded_2_clustered_2024.rds")
```

[코드 7-5] 배치 효과 확인하기
```{r}
# pdf("./results/UMAP_TSNE_by_run.pdf", width = 10)
Idents(pbmc_alzheimer_SCT.combined) <-  pbmc_alzheimer_SCT.combined@meta.data[["Run"]]
DimPlot(pbmc_alzheimer_SCT.combined, label = F, label.size = 7, reduction = "umap")
DimPlot(pbmc_alzheimer_SCT.combined, label = F, label.size = 7, reduction = "tsne")
# dev.off()

# pdf("./results/UMAP_TSNE_by_run_split.pdf", width = 15)
Idents(pbmc_alzheimer_SCT.combined) <-  pbmc_alzheimer_SCT.combined@meta.data[["Run"]]
DimPlot(pbmc_alzheimer_SCT.combined, label = F, label.size = 7, reduction = "umap", split.by = "Run")
DimPlot(pbmc_alzheimer_SCT.combined, label = F, label.size = 7, reduction = "tsne", split.by = "Run")
# dev.off()

# pdf("./results/UMAP_TSNE_by_age.pdf", width = 10)
Idents(pbmc_alzheimer_SCT.combined) <-  pbmc_alzheimer_SCT.combined@meta.data[["Age"]]
DimPlot(pbmc_alzheimer_SCT.combined, label = F, label.size = 7, reduction = "umap")
DimPlot(pbmc_alzheimer_SCT.combined, label = F, label.size = 7, reduction = "tsne")
# dev.off()

# pdf("./results/UMAP_TSNE_by_age_split.pdf", width = 15)
Idents(pbmc_alzheimer_SCT.combined) <-  pbmc_alzheimer_SCT.combined@meta.data[["Age"]]
DimPlot(pbmc_alzheimer_SCT.combined, label = F, label.size = 7, reduction = "umap", split.by = "Age")
DimPlot(pbmc_alzheimer_SCT.combined, label = F, label.size = 7, reduction = "tsne", split.by = "Age")
# dev.off()
```


[방법 2] 이어서 
```{r}
pbmc_alzheimer_2_SCT <- RunPCA(pbmc_alzheimer_2_SCT, verbose = FALSE)
pbmc_alzheimer_2_SCT <- RunUMAP(pbmc_alzheimer_2_SCT, reduction = "pca", dims = 1:30, verbose = FALSE)
pbmc_alzheimer_2_SCT <- FindNeighbors(pbmc_alzheimer_2_SCT, reduction = "pca", dims = 1:30)
pbmc_alzheimer_2_SCT <- FindClusters(pbmc_alzheimer_2_SCT, resolution = 0.3)

# 혹은 다음과 같이 한번에 실행 가능합니다. 
pbmc_alzheimer_2_SCT <- RunPCA(pbmc_alzheimer_2_SCT, npcs = 30, verbose = FALSE) %>% # 메모리가 부족하면 (64GB 미만) 터질 수 있습니다.
                            RunUMAP(reduction = "pca", dims = 1:30, verbose = FALSE) %>%
                            FindNeighbors(reduction = "pca", dims = 1:30, verbose = FALSE) %>%
                            FindClusters(resolution = 0.7, verbose = FALSE)  #  vst.flavor = "v2", 
# saveRDS(pbmc_alzheimer_2_SCT, "./rds/pbmc_alzheimer_2_SCT.rds")
```

UMAP

# 08 배치 효과 교정 
```{r}
pbmc_alzheimer_SCT.combined <- readRDS("./pbmc_alzheimer_SCT.combinded_2_clustered_2024.rds")
```

```{r}
# only integrated PC values are exist not the count dataset 
dim(pbmc_alzheimer_SCT.combined@reductions$integrated.cca@cell.embeddings)
pbmc_alzheimer_SCT.combined@reductions$integrated.cca@feature.loadings

pbmc_alzheimer_SCT.combined@assays$integrated@data[1:10, 1:10] # only 2000 features from SCT normalized
pbmc_alzheimer_SCT.combined@assays$integrated@scale.data[1:10, 1:10] # 좀 다르군 scaling 은 된것같다. 10 max 

summary(pbmc_alzheimer_SCT.combined@assays$integrated@scale.data[1:10, 1:10])
summary(pbmc_alzheimer_SCT.combined@assays$integrated@data[1:10, 1:10])

pbmc_alzheimer_SCT.combined@assays$SCT
```

```{r}
#2024.02.01 try other integration on SCT
dim(pbmc_alzheimer_SCT.combined@reductions$integrated.cca@cell.embeddings)
# RNA - counts, data, scaled.data
# SCT - counts, data, scaled.data
# Integrated - data, scaled.data

dim(pbmc_alzheimer_SCT.combined@assays$RNA$counts) # 24164, 74134
dim(pbmc_alzheimer_SCT.combined@assays$SCT@counts) # 21737 74134
dim(pbmc_alzheimer_SCT.combined@assays$integrated$data) # 2000, 74134
dim(pbmc_alzheimer_SCT.combined@assays$integrated$scale.data) # 2000, 74134
identical(pbmc_alzheimer_SCT.combined@assays$integrated$data, pbmc_alzheimer_SCT.combined@assays$integrated$scale.data) # FALSE

pbmc_alzheimer_SCT.combined@assays$SCT@counts[1:5,1:5]
pbmc_alzheimer_SCT.combined@assays$integrated$data[1:5,1:5]
pbmc_alzheimer_SCT.combined@assays$integrated$scale.data[1:5,1:5]
dim(pbmc_alzheimer_SCT.combined@assays$SCT@scale.data) # 2000, 74134
```

```{r}
# SCTransform object -> merge -> dimensionreduction
# SCT_merged <- FindVariableFeatures(SCT_merged) # 안됨 features 이용
# SCT_merged@assays$SCT@SCTModel.list
# features <- SelectIntegrationFeatures(object.list = SCT_merged, nfeatures = 3000)

VariableFeatures(SCT_merged) <- features

SCT_merged <- RunPCA(SCT_merged, verbose = FALSE) %>%
  RunUMAP(., reduction = "pca", dims = 1:20, verbose = FALSE) %>%
  RunTSNE(., reduction = "pca", dims = 1:20, verbose = FALSE) %>%
  FindNeighbors(., reduction = "pca", dims = 1:20) %>% 
  FindClusters(., resolution = c(0.1, 0.3, 0.5))
```


[코드 8-1]
```{r}
# memory.limit() # Inf
# options(future.globals.maxSize = 3e+09)
# memory.limit(size = NA)
DefaultAssay(pbmc_alzheimer_SCT.combined) <- "SCT"

obj_SCT <- IntegrateLayers(  
  # 커서 안돌아가는게 아니고, no applicable method for 'Assays' applied to an object of class "NULL" - Integrated였네 ㅎ 아차차 
  # Error in getGlobalsAndPackages(expr, envir = envir, globals = globals) : 
  # The total size of the 10 globals exported for future expression (‘FUN()’) is 3.12 GiB.. This exceeds the maximum allowed size of 2.79 GiB (option 'future.globals.maxSize'). The three largest globals are ‘object.list’ (3.12 GiB of class ‘list’), ‘NNHelper’ (93.29 KiB of class ‘function’) and ‘FUN’ (21.25 KiB of class ‘function’)
  object = pbmc_alzheimer_SCT.combined,
  method = HarmonyIntegration,
  normalization.method = "SCT",
  new.reduction = "integrated.harmony", 
  verbose = F
)

obj_SCT <- FindNeighbors(obj_SCT, reduction = "integrated.harmony", dims = 1:30)
# obj_SCT <- FindClusters(obj_SCT, resolution = 2, cluster.name = "harmony_clusters")
obj_SCT <- RunUMAP(obj_SCT, reduction = "integrated.harmony", dims = 1:30, reduction.name = "umap.sct.harmony")
obj_SCT

# pdf("./results/UMAP_SCT_harmony.pdf")
DimPlot(
  obj_SCT,
  reduction = "umap.sct.harmony",
  group.by = c("Age"),
  combine = FALSE, label.size = 2
)
# dev.off()

obj_SCT[["SCT"]] <- JoinLayers(obj_SCT[["SCT"]]) # 이걸 합치려면
obj_SCT[["RNA"]]
obj_SCT@assays$RNA
obj_SCT@assays$SCT

obj_SCT[["SCT"]]

class(obj_SCT)
class(obj_SCT[["RNA"]])
class(obj_SCT[["SCT"]])

JoinLayers(obj_SCT)

dim(obj_SCT[["SCT"]]$scale.data)
identical(pbmc_alzheimer_SCT.combined[["SCT"]]$scale.data, obj_SCT[["SCT"]]$scale.data) # TRUE
identical(pbmc_alzheimer_SCT.combined@assays$SCT$counts, obj_SCT@assays$SCT$counts) # TRUE
```

## After Log normalization 
```{r}
obj <- pbmc_alzheimer_SCT.combined
DefaultAssay(obj) <- "RNA"
obj <- NormalizeData(obj)
obj <- FindVariableFeatures(obj)
obj <- ScaleData(obj)
obj <- RunPCA(obj) # PC 50

obj <- IntegrateLayers(object = obj, method = CCAIntegration, orig.reduction = "pca", new.reduction = "integrated.cca")
# saveRDS(obj, "./rds/RNA_CCA_test.rds")
obj <- readRDS("./rds/RNA_CCA_test.rds")


# 'Run' = 샘플 이름 추가하기 
obj@meta.data <- obj@meta.data %>%
  mutate(Run = ifelse(grepl("_1", rownames(.)), "SRR13911909", 
                              ifelse(grepl("_2", rownames(.)), "SRR13911910",
                                     ifelse(grepl("_3", rownames(.)), "SRR13911911",
                                            ifelse(grepl("_4", rownames(.)), "SRR13911912",
                                                   ifelse(grepl("_5", rownames(.)), "SRR13911913",
                                                          ifelse(grepl("_6", rownames(.)), "SRR13911914", "NA")))))))

# manifest
manifest <- read.csv("../singleCell_practice/SraRunTable.txt")
manifest <- manifest %>% # 필요한 컬럼만 추출해내기 
  select(c(Run, Age, subject_status))

obj@meta.data[c("Run", "Age", "subject_status")] <-
  manifest[match(obj$Run, manifest$Run), ]
```

IntegrateLayers(
  object,
  method,
  orig.reduction = "pca",
  assay = NULL,
  features = NULL,
  layers = NULL,
  scale.layer = "scale.data",
  ...
)

IntegrateLayers() 함수는 PCA 와 scaled.data를 이용합니다. 
dim(pbmc_alzheimer_SCT.combined@assays$RNA$scale.data) # 2000, 74134



```{r}
obj <- FindNeighbors(obj, reduction = "integrated.cca", dims = 1:30)
obj <- FindClusters(obj, resolution = 2, cluster.name = "cca_clusters")
obj <- RunUMAP(obj, reduction = "integrated.cca", dims = 1:30, reduction.name = "umap.rna.cca")

DimPlot(
  obj,
  reduction = "umap.rna.cca",
  group.by = c("Age"),
  combine = FALSE, label.size = 2
)

DimPlot(
  obj,
  reduction = "umap",
  group.by = c("Age"),
  combine = FALSE, label.size = 2
)


DimPlot(
  obj,
  reduction = "integrated",
  group.by = c("Age"),
  combine = FALSE, label.size = 2
)

```
Once integrative analysis is complete, you can rejoin the layers - which collapses the individual datasets together and recreates the original counts and data layers. You will need to do this before performing any differential expression analysis. However, you can always resplit the layers in case you would like to reperform integrative analysis.
https://satijalab.org/seurat/articles/seurat5_integration 

UMAP 상에서 integration 이 된것 같으면 JoinLayers() 함수를 실행해서 실제 카운트를 합쳐 새로운 counts 와 data 레이어를 만들어 낼 수 있습니다. 

```{r}
DefaultAssay(obj) <- "RNA" # integrated didn't work for IntegrateLayers, SCT also doesn't work 
obj[["RNA"]] <- JoinLayers(obj[["RNA"]])
obj[["RNA"]]

pbmc_alzheimer_SCT.combined
obj
pbmc_alzheimer_SCT.combined[["RNA"]]
obj[["RNA"]]

identical(pbmc_alzheimer_SCT.combined[["RNA"]]$scale.data, obj[["RNA"]]$scale.data) # TRUE
obj[["RNA"]]$data # 24164 x 74134
obj[["RNA"]]$count # 24164 x 74134
```


# Finding DE features
```{r}
# 2024.03.10 
pbmc_alzheimer_SCT.anchors <- readRDS("./rds/pbmc_alzheimer_SCT.anchors.rds")

pbmc_alzheimer_SCT.combined <- IntegrateData(anchorset = pbmc_alzheimer_SCT.anchors, normalization.method = "SCT") # 메모리가 부족하면 (64GB 미만) 터질 수 있습니다.
# saveRDS(pbmc_alzheimer_SCT.combined, "./rds/sobj_SCT_merged_method.rds")
```

```{r}
# 마커 찾기
DefaultAssay(pbmc_alzheimer_SCT.combined) <- "integrated"
Idents(pbmc_alzheimer_SCT.combined) <- "integrated_snn_res.0.3"
pbmc_alzheimer_SCT.combined <- PrepSCTFindMarkers(object = pbmc_alzheimer_SCT.combined)
markers <- FindAllMarkers(pbmc_alzheimer_SCT.combined , only.pos = TRUE) # only positive for now
# saveRDS(markers, "./rds/markers_0.3.rds") # resaved on 2024.03.23 after PrepSCTFindMarkers

# log2FC 값이 1 이상인 마커 
markers_log2FC_1 <- markers %>%
    group_by(cluster) %>%
    dplyr::filter(avg_log2FC > 1)

# 각 클러스터별 top 10개 마커 
markers %>%
    group_by(cluster) %>%
    dplyr::filter(avg_log2FC > 1) %>%
    slice_head(n = 10) %>%
    ungroup() -> top10

markers[markers$gene %in% "CD21",]
View(top10)
```


# 09 Annotation

## 09-01 세포 특정 마커 이용
marker features 구하고 -> 알려진 cell type specific gene 이용하기 
```{r}
```

## 09-02 Seurat 참조 맵핑 (reference mapping) 이용하기 

먼저 참조 데이터를 다운로드 받아줍니다. 저희는 Seurat 에서 제공하는 말초 혈액 세포 참조데이터를 이용하겠습니다. https://zenodo.org/records/7779017#.ZCMojezMJqs 에서 직접 다운을 받거나 다음과 같이 R 코드로 다운받을 수 있습니다. 

[코드 9-1] 참조 데이터 Seurat 오브젝트 다운로드 
```{r}
# 다운받을 데이터의 URL 
url <- "https://zenodo.org/records/7779017/files/pbmc_multimodal_2023.rds?download=1"

# 파일 이름과, 저장 위치 정한 후 데이터 다운로드 받기 
file_name <- "pbmc_multimodal_2023.rds"
file_path <- "../data/"
download.file(url, paste(file_path, file_name, sep = ""), mode = "wb")

# 데이터 읽기 
pbmc_multimodal_2023 <- readRDS("../data/pbmc_multimodal_2023.rds")
```


_FindTransferAnchors()_ 을 이용해서 참조데이터와 우리 데이터의 공통된 지점인 anchors을 찾을 수 있으며,
추후, 해당 anchors와 _TransferData_ 함수를 이용해서 참조오브젝트의 데이터를 저희의 오브젝트에 옮길 수 있습니다. 

[코드 9-2] 참조 데이터를 이용한 세포유형 맵핑
```{r}
pbmc_alzheimer_SCT.combined_ori <- readRDS("./rds/pbmc_alzheimer_SCT.combinded_2_clustered_2024.rds")

# DefaultAssay() <- "integrated"
# anchor <- FindTransferAnchors(
# 	reference = pbmc_multimodal_2023,
# 	query = pbmc_alzheimer_SCT.combined, # Pearson residuals 
# 	reference.reduction = "spca",
# 	normalization.method = "SCT",
# 	dims = 1:50
# )
# ERROR 1
# Normalizing query using reference SCT model
# Warning: No layers found matching search pattern providedWarning: npcs is smaller than the largest value requested by the dims parameter.
# Setting npcs to 50 and continuing.Warning: Layer ‘scale.data’ is emptyPerforming PCA on the provided reference using 0 features as input.
# Error in PrepDR(object = object, features = features, verbose = verbose) : 
#   Variable features haven't been set. Run FindVariableFeatures() or provide a vector of feature names.

# TRIED 1
# DefaultAssay(pbmc_alzheimer_SCT.combined) <- "SCT"
# pbmc_alzheimer_SCT.combined <- FindVariableFeatures(pbmc_alzheimer_SCT.combined, selection.method = "vst", nfeatures = 2000)
# TRIED 1 ERROR  SCT assay is comprised of multiple SCT models. To change the variable features, please set manually with VariableFeatures<-
# 즉, SCTransform 을 다시 돌려야 한다. 
# BiocManager::install('glmGamPoi')
# pbmc_alzheimer_SCT.combined <- SCTransform(pbmc_alzheimer_SCT.combined, vars.to.regress = "percent.mt", verbose = FALSE)  
# SAME ERROR 

# TRIED 2
# pbmc_alzheimer_SCT.combined <- PrepSCTFindMarkers(object = pbmc_alzheimer_SCT.combined) # https://satijalab.org/seurat/reference/prepsctfindmarkers]
# COMPARE scale.data(SAME), data(DIFFERENT), counts(DIFFERENT)
# identical(pbmc_alzheimer_SCT.combined_ori[["SCT"]]$scale.data, pbmc_alzheimer_SCT.combined[["SCT"]]$scale.data) # SAME
# identical(pbmc_alzheimer_SCT.combined_ori[["SCT"]]$data, pbmc_alzheimer_SCT.combined[["SCT"]]$data) # DIFFERENT 
# identical(pbmc_alzheimer_SCT.combined_ori[["SCT"]]$counts, pbmc_alzheimer_SCT.combined[["SCT"]]$counts) # COUNT

# TRIED 3 
# no scale.data in reference, but again, since assay is SCT already i don't see a reason of SCTransform -> let's not do thit

# TRIED 4
anchor <- FindTransferAnchors(
	reference = pbmc_multimodal_2023,
	query = pbmc_alzheimer_SCT.combined,
	reference.reduction = "spca",
	reference.assay = "SCT",
	query.assay = "integrated",
	normalization.method = "SCT",
	dims = 1:50
)


pbmc_alzheimer_SCT.combined <- MapQuery(
	anchorset = anchor,
	query = pbmc_alzheimer_SCT.combined,
	reference = pbmc_multimodal_2023,
	refdata = list(celltype.l1 = "celltype.l1", celltype.l2 = "celltype.l2"),
	reduction.model = "wnn.umap"
)

pdf("./results/UMAP_reference_mapping_l1.pdf")
DimPlot(pbmc_alzheimer_SCT.combined, reduction = "ref.umap", group.by = "predicted.celltype.l1", label = T)
DimPlot(pbmc_alzheimer_SCT.combined, reduction = "umap", group.by = "predicted.celltype.l1", label = T)
dev.off()

pdf("./results/UMAP_reference_mapping_l2.pdf", width = 13)
DimPlot(pbmc_alzheimer_SCT.combined, reduction = "ref.umap", group.by = "predicted.celltype.l2", label = T)
DimPlot(pbmc_alzheimer_SCT.combined, reduction = "umap", group.by = "predicted.celltype.l2", label = T)
dev.off()
```
```{r}
# TEST 
# 다운받을 데이터의 URL  https://zenodo.org/records/4546839 
# url <- "https://zenodo.org/records/7779017/files/pbmc_multimodal_2023.rds?download=1"
# 
# # 파일 이름과, 저장 위치 정한 후 데이터 다운로드 받기 
# file_name <- "Human_PBMC.rds"
# file_path <- "../data/"
# download.file(url, paste(file_path, file_name, sep = ""), mode = "wb")
# 
# # 데이터 읽기 
# Human_PBMC <- readRDS("../data/Human_PBMC.rds")
```

## 09-03 외부 프로그램 이용 
  - Azimuth 
  - SingleR
  - scType
  - scanVI

### singleR 
HumanPrimaryCellAtlasData
```{r}
# Loading reference data with Ensembl annotations.
# BiocManager::install("celldex")
library(celldex)
# devtools::install_version("dbplyr", version = "2.3.4") # https://stackoverflow.com/questions/77370659/error-failed-to-collect-lazy-table-caused-by-error-in-db-collect-using\
# library(dbplyr)
ref.data <- HumanPrimaryCellAtlasData(ensembl=F)

## singeR 
devtools::install_github('dviraran/SingleR')
library(SingleR)
library(Seurat)
sobj_SCE <- as.SingleCellExperiment(sobj_SCT_merged_method_1_clustered, assay="SCT")
# ref_SCE <- as.SingleCellExperiment(ref.data, assay="SCT") # not work for both RNA, SCT
# invalid class “Seurat” object: 1: all cells in graphs must be present in the Seurat object
results <- SingleR(test = sobj_SCE, ref = ref.data, labels = ref.data$label.main) 
# write.csv(results, "./sobj_SCT_merged_method_1_clustered_singleR.csv")
```

```{r, fig.width= 15}
sobj_SCT_merged_method_1_clustered$singleR_label <- results$labels
sobj_SCT_merged_method_1_clustered$singleR_pruned_label <- results$pruned.labels
Idents(sobj_SCT_merged_method_1_clustered) <- sobj_SCT_merged_method_1_clustered$singleR_pruned_label # or singleR_label
Idents(sobj_SCT_merged_method_1_clustered) <- sobj_SCT_merged_method_1_clustered$integrated_snn_res.0.3 # or singleR_label
DimPlot(sobj_SCT_merged_method_1_clustered, label = T, reduction = "umap")

## 3D UMAP 
```

```{r, fig.width = 15}
# 2023.11.29
sobj_SCE <- as.SingleCellExperiment(sobj_SCT_merged_method_1, assay="SCT")
results <- SingleR(test = sobj_SCE, ref = ref.data, labels = ref.data$label.main) 
sobj_SCT_merged_method_1$singleR_label <- results$labels
sobj_SCT_merged_method_1$singleR_pruned_label <- results$pruned.labels
Idents(sobj_SCT_merged_method_1) <- sobj_SCT_merged_method_1$singleR_pruned_label # or singleR_label
DimPlot(sobj_SCT_merged_method_1, label = T, reduction = "umap")
```

MonacoImmuneData
```{r, fig.width=15}
library(celldex)
library(SingleR)
ref.data <- celldex::MonacoImmuneData(ensembl=F)
ref.data

# singleR 이용해서 
# sobj_SCE <- as.SingleCellExperiment(sobj_SCT_merged_method_1, assay="SCT")
sobj_SCE <- as.SingleCellExperiment(pbmc_alzheimer_SCT.combined, assay="SCT")
results <- SingleR(test = sobj_SCE, ref = ref.data, labels = ref.data$label.main) 
results <- SingleR(test = sobj_SCE, ref = ref.data, labels = ref.data$label.main) 

results
ref.data

pbmc_alzheimer_SCT.combined$MonacoImmuneData_main <- results$labels
pbmc_alzheimer_SCT.combined$MonacoImmuneData_pruned <- results$pruned.labels

Idents(pbmc_alzheimer_SCT.combined) <- pbmc_alzheimer_SCT.combined$MonacoImmuneData_pruned # or singleR_label
DimPlot(pbmc_alzheimer_SCT.combined, label = T, reduction = "umap") 

# pdf("../singleCell_practice/results/UMAP_manacoimmundata.pdf", width = 10)
Idents(pbmc_alzheimer_SCT.combined) <- pbmc_alzheimer_SCT.combined$MonacoImmuneData_main # or singleR_label 
DimPlot(pbmc_alzheimer_SCT.combined, label = T, reduction = "umap") 
# dev.off()
```

### ScType

[코드 9-] 필요한 툴 및 함수들 다운받기 
```{r}
# 필요한 라이브러리 불러오기  
BiocManager::install("HGNChelper")
library(HGNChelper)
library(openxlsx) # 엑셀 파일을 다루기 

# load gene set preparation function
source("https://raw.githubusercontent.com/IanevskiAleksandr/sc-type/master/R/gene_sets_prepare.R")
# load cell type annotation function
source("https://raw.githubusercontent.com/IanevskiAleksandr/sc-type/master/R/sctype_score_.R")

# 사용 할 유전자 마커 데이터 베이스 불러오기 ()
db_ = "https://raw.githubusercontent.com/IanevskiAleksandr/sc-type/master/ScTypeDB_full.xlsx";
tissue = "Immune system"
gs_list = gene_sets_prepare(db_, tissue)
gs_list
```

```{r}
# 유전자 발현 데이터를 불러와 세포 유형을 지정합니다.
es.max = sctype_score(scRNAseqData =  pbmc_alzheimer_SCT.combined[["integrated"]]@scale.data, scaled = TRUE,
                      gs = gs_list$gs_positive, gs2 = gs_list$gs_negative) 

# 클러스터 별로 합쳐줍니다.
cL_resutls = do.call("rbind", lapply(unique(pbmc_alzheimer_SCT.combined@meta.data$integrated_snn_res.0.3), function(cl){
    es.max.cl = sort(rowSums(es.max[ ,rownames(pbmc_alzheimer_SCT.combined@meta.data[pbmc_alzheimer_SCT.combined@meta.data$integrated_snn_res.0.3==cl, ])]), decreasing = !0)
    head(data.frame(cluster = cl, type = names(es.max.cl), scores = es.max.cl, ncells = sum(pbmc_alzheimer_SCT.combined@meta.data$integrated_snn_res.0.3==cl)), 10)
}))

sctype_scores = cL_resutls %>% group_by(cluster) %>% top_n(n = 1, wt = scores)  
sctype_scores


# 확실하지 않은 (ScType 점수가 낮은) 클러스터는 "unknown"으로 지정해줍니다.
sctype_scores$type[as.numeric(as.character(sctype_scores$scores)) < sctype_scores$ncells/4] = "Unknown"
print(sctype_scores[,1:3])
```

```{r}
pbmc_alzheimer_SCT.combined@meta.data$customclassif = ""
for(j in unique(sctype_scores$cluster)){
  cl_type = sctype_scores[sctype_scores$cluster==j,]; 
  pbmc_alzheimer_SCT.combined@meta.data$customclassif[pbmc_alzheimer_SCT.combined@meta.data$integrated_snn_res.0.3 == j] = as.character(cl_type$type[1])
}

# pdf("../singleCell_practice/results/UMAP_scType.pdf", width = 10)
DimPlot(pbmc_alzheimer_SCT.combined, reduction = "umap", label = TRUE, repel = TRUE, group.by = 'customclassif') 
# dev.off()
```

```{r}
# 함수 불러오기
source("https://raw.githubusercontent.com/IanevskiAleksandr/sc-type/master/R/auto_detect_tissue_type.R")
db_ = "https://raw.githubusercontent.com/IanevskiAleksandr/sc-type/master/ScTypeDB_full.xlsx";

# 조직 유형 유추하기 (이거 오래 걸림)
tissue_guess = auto_detect_tissue_type(path_to_db_file = db_, seuratObject = pbmc_alzheimer_SCT.combined, scaled = TRUE, assay = "SCT")        
 # error in evaluating the argument 'x' in selecting a method for function 'as.matrix': no slot of name "data_type" for this object of class "SCTAssay"
# assay = "integrated"
# Error in h(simpleError(msg, call)) : 
#   error in evaluating the argument 'x' in selecting a method for function 'rowSums': incorrect number of
```

```{r}
library(job)
job::job({
  saveRDS(pbmc_alzheimer_SCT.combined, "./rds/pbmc_alzheimer_SCT.combinded_2_clustered_20240629.rds")  
})
# pbmc_alzheimer_SCT.combined <- readRDS("./rds/pbmc_alzheimer_SCT.combinded_2_clustered_20240629.rds")
```

### ScanVI
** posit에서 reticulate 실행 불가 for now 
[코드 9-] scanVI 를 위한 라이브러리 설치 및 Seurat 오브젝트 변환 
```{r}
install.packages("reticulate") # python함수를 R에서 사용가능하게 도와주는 라이브러리 (TODO : 체크 하기) 
install.packages("cowplot")    # ggplot를 활용한 시각화를 도와주는 툴 
# install.packages("devtools")   # CRAN뿐 아니라 github, bioconductor 등에서도 쉽게 라이브러리를 설치 할 수 있도록 도와주는 툴 
library(devtools)
devtools::install_github("cellgeni/sceasy")
library(reticulate)
library(cowplot)
library(sceasy)

# Seurat 오브젝트를 AnnData 오브젝트로 변형하기 
sc <- import("scanpy", convert = FALSE)
scvi <- import("scvi", convert = FALSE)
adata <- convertFormat(pbmc_alzheimer_SCT.combined, from="seurat", to="anndata", main_layer="counts", drop_single_values=FALSE)
print(adata) # Note generally in Python, dataset conventions are obs x var
```




# 챕터 10 단일 세포 데이터 후속 분석 
```{r}
pbmc_alzheimer_SCT.combined[[]] <- pbmc_alzheimer_SCT.combined[[]] %>%
  mutate(customclassif = gsub(" |  ", "_", customclassif))
```


[코드 10-1] 그룹간 차등 유전자 발현(DEG) 분석 실행하기 
```{r}
# 그룹 에세이와식별자 설정
DefaultAssay(pbmc_alzheimer_SCT.combined) <- "SCT"
Idents(pbmc_alzheimer_SCT.combined) <- "subject_status"

# 중증 환자 vs 일반인 차등 발현 유전자
# SCT
degs_severeADvsnormal <- FindMarkers(pbmc_alzheimer_SCT.combined, ident.1 = "patient with severe AD", ident.2 = "normal individual", only.pos = FALSE)

# 경증 환자 vs 일반인 차등 발현 유전자
degs_mildADvsnormal <- FindMarkers(pbmc_alzheimer_SCT.combined, ident.1 = "patient with mild AD", ident.2 = "normal individual", only.pos = FALSE)

# avg_log2FC 절댓값으로 내림차순 정렬하기
degs_severeADvsnormal <- degs_severeADvsnormal %>%
  arrange(-abs(avg_log2FC))
degs_mildADvsnormal <- degs_mildADvsnormal %>%
  arrange(-abs(avg_log2FC))
```
[코드 10-2] 데이터 프레임 csv 형태로 저장하기  
```{r}
write.csv(degs_severeADvsnormal, "../results/all_degs_severeADvsnormal.csv", row.names=F) 
write.csv(degs_mildADvsnormal, "../results/all_degs_mildADvsnormal.csv", row.names=F) 
```


[코드 10-3] 차등 발현 유전자 시각화 
```{r fig.height=10}
# set up 
Idents(pbmc_alzheimer_SCT.combined) <- "subject_status"
DefaultAssay(pbmc_alzheimer_SCT.combined) <- "SCT"

# VlnPlot
VlnPlot(pbmc_alzheimer_SCT.combined, features = rownames(degs_severeADvsnormal)[1:6],
        layer = "data", log = TRUE)

# RidgePLot 
RidgePlot(pbmc_alzheimer_SCT.combined, features = rownames(degs_severeADvsnormal)[1:6],
        layer = "data")

# Feature Plot 
FeaturePlot(pbmc_alzheimer_SCT.combined, features = rownames(degs_severeADvsnormal)[1:2], split.by = "subject_status")
```


[코드 10-4] 세포 유형별 차등 발현 유전자(DEG) 분석 실행하기 
```{r}
# 세포 유형별 차등 유전자 발현(DEG) 분석 함수 
run_DEGs_per_celltype <- function(seurat_obj, celltype){
  
  # 특정 세포 유형으로만 이루어진 슈랏 오브젝트 부분 추출하기 
  sobj_sub <- subset(x = seurat_obj, subset = customclassif == celltype)
  
  # 특정 세포 유형에서 차등 발현 유전자 구하기 
  Idents(sobj_sub) <- "subject_status"
  sobj_sub <- PrepSCTFindMarkers(object = sobj_sub)

  ## 중증 환자 vs 일반인 
  degs_severeADvsnormal <- FindMarkers(sobj_sub, ident.1 = "patient with severe AD", ident.2 = "normal individual", only.pos = FALSE, recorrect_umi=FALSE)
  ## 경증 환자 vs 일반인 
  degs_mildADvsnormal <- FindMarkers(sobj_sub, ident.1 = "patient with mild AD", ident.2 = "normal individual", only.pos = FALSE, recorrect_umi=FALSE)
  
  # avg_log2FC 값으로 내림차순 정렬하기 
  degs_severeADvsnormal <- degs_severeADvsnormal %>% 
    arrange(-(avg_log2FC)) 
  degs_mildADvsnormal <- degs_mildADvsnormal %>% 
    arrange(-(avg_log2FC)) 
  
  # 차등 발현 유전자 csv 로 저장하기 
  write.csv(degs_severeADvsnormal, glue::glue( "./results/{celltype}_degs_severeADvsnormal.csv"), row.names = T)
  write.csv(degs_mildADvsnormal, glue::glue( "./results/{celltype}_degs_mildADvsnormal.csv"), row.names = T )
  
  return(sobj_sub)
}

# 각 세포유형 마다 실행하기 (실행한 후 커피한잔 하고 오세요)
sobj_subsets_list <- list()
DefaultAssay(pbmc_alzheimer_SCT.combined) <- "SCT"
for (celltype in unique(pbmc_alzheimer_SCT.combined$customclassif)){ # using scTYPE celltype
  print(glue::glue("### {celltype} is processing ... "))
  sobj_subset <- run_DEGs_per_celltype(pbmc_alzheimer_SCT.combined, celltype)
  
  # 부분 추출 된 슈랏 오브젝트들을 리스트에 추가하기  
  sobj_subsets_list[[celltype]] <- sobj_subset
}

# 후속 분속에 이용하기 위하여 저장하기 
saveRDS(sobj_subsets_list, "./rds/sobj_sebsets_list.rds")
sobj_subsets_list 
```


[코드 10-5] b 세포의 차등 발현 유전자 데이터 확인하기 
```{r}
# b 세포의 차등 발현 유전자 데이터 확인하기 
degs_bcell <- read.csv("./results/Naive_B_cells_degs_severeADvsnormal.csv", stringsAsFactors = FALSE)
degs_bcell_0.05 <- degs_bcell %>%
  filter(p_val_adj < 0.05) %>%
  arrange(-abs(avg_log2FC))

# 상향 조절 유전자 들여다보기 
degs_bcell_up <- degs_bcell_0.05 %>% 
  filter(avg_log2FC > 0)

# 하양 조절 유전자 들여다보기
degs_bcell_down <- degs_bcell_0.05 %>% 
  filter(avg_log2FC < 0)
```

[코드 10-6] B 세포의 차등 발현 유전자 발현 패턴 시각화: 히트맵 
```{r, fig.width = 10}
# Seurat의 DoHeatmap 이용 
sobj_subsets_list$`Naive B cells`
DefaultAssay(sobj_subsets_list$`Naive B cells`) <- "SCT"
DoHeatmap(sobj_subsets_list$`Naive B cells`, features = c(degs_bcell_up$X[1:20], degs_bcell_down$X[1:20]),
          slot= "data", size = 4, angle = 0, hjust = 0.5) + 
  ggtitle("Top 30 DEGs of Naive B cell")

# per group 
group_means <- AggregateExpression(sobj_subsets_list$`Naive B cells`, group.by = "subject_status")
degs_bcell_up %>%
  filter(p_val_adj)
group_means_matrix_sub <- group_means$RNA[c(degs_bcell_up$X[1:200], degs_bcell_down$X[1:200]),]
group_means_matrix_sub <- group_means$RNA[degs_bcell_0.05$X,]

# Create the heatmap
pheatmap(group_means_matrix_sub, 
         cluster_rows = FALSE, 
         cluster_cols =FALSE, 
         show_rownames = FALSE, 
         show_colnames = TRUE,
         angle_co= 0 ,
         scale = "row", 
         main = "Naive B CELL DEGs",
         breaks = seq(-1, 1, length.out = 101),
         color = colorRampPalette(c("blue", "white", "red"))(100)) 
```

[코드 10-7] B 세포에서의 차등 발현 유전자 박스 플롯 그리기 
```{r, fig.width = 12}
# test <- sobj_subsets_list$B_cell@assays$SCT$counts[degs_bcell[1:10, ]$X, ]
# test <- as.data.frame(test)
# log10(test+1)
# boxplot(t(test))

Idents(pbmc_alzheimer_SCT.combined) <- "subject_status"
DefaultAssay(pbmc_alzheimer_SCT.combined) <- "SCT"

sobj_bcell <- sobj_subsets_list$`Naive B cells`
DefaultAssay(sobj_bcell) <- "SCT"
RidgePlot(sobj_bcell, features = degs_bcell[1:6, ]$X, ncol = 2, layer = "data", , log = TRUE)

VlnPlot(pbmc_alzheimer_SCT.combined, features = degs_bcell[1:6, ]$X, layer = "data", log = TRUE)
```

[코드 10-8] B 세포 재클러스터링  
pbmc_alzheimer_SCT.combined@graphs$integrated_nn (nn: kNN graph , snn: shared NN graph)
```{r fig.width = 7}
# [1] 원래 데이터 이용하기 
Idents(pbmc_alzheimer_SCT.combined) <- "customclassif"
pbmc_alzheimer_SCT.combined <- FindSubCluster(
  pbmc_alzheimer_SCT.combined,
  "Naive_B_cells",
  graph.name = "integrated_nn",
  subcluster.name = "sub.cluster",
  resolution = 0.5,
  algorithm = 1
)
# 시각화 
DimPlot(test, group.by = "sub.cluster")


# [2] B 세포 부분 데이터 이용하기 
Bcells_subset <- sobj_subsets_list$`Naive B cells`
Bcells_subset <- FindClusters(Bcells_subset, resolution = 0.5, graph.name ="integrated_nn", cluster.name = "B Cells' subclusters")
# 시각화 
DimPlot(Bcells_subset, group.by = "B Cells' subclusters")
```


Time series
```{r, fig.width = 12}
DimPlot(pbmc_alzheimer_SCT.combined, split.by = "subject_status", group.by = "customclassif", label.size = 2) + 
  theme(legend.text = element_text(size = 8))
```


# 챕터 11 

## 11.3 network regulon inference 
```{r}
# 필요한 패키지 설치
install.packages("BiocManager")
BiocManager::install(c("Seurat", "AUCell", "SCENIC"))
install.packages("devtools")
devtools::install_github("aertslab/GRNBoost2")

# 패키지 로드
library(Seurat)
library(SCENIC)
library(AUCell)
library(GRNBoost2)

# Seurat 객체에서 유전자 발현 데이터 추출
expr_matrix <- as.matrix(GetAssayData(seurat_object, slot = "data"))

# 유전자 목록과 세포 목록 추출
genes <- rownames(expr_matrix)
cells <- colnames(expr_matrix)

# GRNBoost 실행
weight_matrix <- GRNBoost2(expr_matrix)

# SCENIC 설정
scenicOptions <- initializeScenic(org="hgnc", dbDir="path/to/databases", nCores=4) # "path/to/databases"를 적절히 수정

# 단계 1: co-expression network 구축
scenicOptions@settings$dbDir <- "path/to/databases" # 데이터베이스 경로 설정
saveRDS(scenicOptions, file="int/scenicOptions.Rds") # 설정 저장

# weight matrix 저장
write.table(weight_matrix, file="int/1.4_GRNBoost_linkList.tsv", sep="\t", row.names=FALSE, col.names=TRUE)

# 단계 2: regulon 구축
scenicOptions <- runSCENIC_1_coexNetwork2modules(scenicOptions)
scenicOptions <- runSCENIC_2_createRegulons(scenicOptions)
scenicOptions <- runSCENIC_3_scoreCells(scenicOptions, expr_matrix)

# AUCell 점수 계산
aucellRankings <- AUCell_buildRankings(expr_matrix, plotStats=TRUE)
aucellResults <- AUCell_calcAUC(regulons, aucellRankings)

# 결과를 Seurat 객체에 추가
seurat_object[["SCENIC_AUC"]] <- CreateAssayObject(data = getAUC(aucellResults))

# UMAP 실행
seurat_object <- RunUMAP(seurat_object, reduction = "pca", dims = 1:10, assay = "SCENIC_AUC")

# 시각화
DimPlot(seurat_object, reduction = "umap", group.by = "seurat_clusters")
```



```{r}
# DefaultAssay(pbmc_alzheimer_SCT.combined) <- "integrated"
# Idents(pbmc_alzheimer_SCT.combined) <- "integrated_snn_res.0.3"
# pbmc_alzheimer_SCT.combined <- PrepSCTFindMarkers(object = pbmc_alzheimer_SCT.combined)
# markers <- FindAllMarkers(pbmc_alzheimer_SCT.combined , only.pos = TRUE)

# markers2 <- FindAllMarkers(pbmc_alzheimer_SCT.combined, only.pos = FALSE)
# saveRDS(markers2, "./rds/markers2.rds") # including neg and pos DEGs
```















